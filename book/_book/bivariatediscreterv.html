<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 üìù Bivariate Discrete Random Variables | üÉè Probability I</title>
  <meta name="description" content="Course Materials" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 üìù Bivariate Discrete Random Variables | üÉè Probability I" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course Materials" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 üìù Bivariate Discrete Random Variables | üÉè Probability I" />
  
  <meta name="twitter:description" content="Course Materials" />
  

<meta name="author" content="Dr.¬†Daniel Flores Agreda (based on the Lecture by Prof.¬†Davide La Vecchia)" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="limittheorems.html"/>
<link rel="next" href="numericalmethods.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://www.unige.ch/gsem/fr/"><img src="img/gsem_en.png" alt="UNIGE Logo" width="200" class ="center"></a></li>
<li><a href="https://moodle.unige.ch/course/view.php?id=7133"><strong>Probability I (Spring 2021)</strong></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this lecture</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#contents"><i class="fa fa-check"></i>Contents</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#practical-information"><i class="fa fa-check"></i>Practical information</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#who-we-are"><i class="fa fa-check"></i>Who we are</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#lectures"><i class="fa fa-check"></i>Lectures</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#exercises"><i class="fa fa-check"></i>Exercises</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#tools"><i class="fa fa-check"></i>Tools</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#a-world-of-data"><i class="fa fa-check"></i><b>1.1</b> A World of Data</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#what-to-expect-from-this-lecture"><i class="fa fa-check"></i><b>1.2</b> What to expect from this Lecture?</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="introduction.html"><a href="introduction.html#one-intuitive-illustration"><i class="fa fa-check"></i><b>1.2.1</b> One intuitive illustration</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#a-quick-reminder-of-mathematics"><i class="fa fa-check"></i><b>1.3</b> A quick reminder of Mathematics</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="introduction.html"><a href="introduction.html#powers-and-logarithms"><i class="fa fa-check"></i><b>1.3.1</b> Powers and Logarithms</a></li>
<li class="chapter" data-level="1.3.2" data-path="introduction.html"><a href="introduction.html#differentiation"><i class="fa fa-check"></i><b>1.3.2</b> Differentiation</a></li>
<li class="chapter" data-level="1.3.3" data-path="introduction.html"><a href="introduction.html#integration"><i class="fa fa-check"></i><b>1.3.3</b> Integration</a></li>
<li class="chapter" data-level="1.3.4" data-path="introduction.html"><a href="introduction.html#sums"><i class="fa fa-check"></i><b>1.3.4</b> Sums</a></li>
<li class="chapter" data-level="1.3.5" data-path="introduction.html"><a href="introduction.html#combinatorics"><i class="fa fa-check"></i><b>1.3.5</b> Combinatorics</a></li>
<li class="chapter" data-level="1.3.6" data-path="introduction.html"><a href="introduction.html#limits"><i class="fa fa-check"></i><b>1.3.6</b> Limits</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="settheory.html"><a href="settheory.html"><i class="fa fa-check"></i><b>2</b> Elements of Set Theory for Probability</a>
<ul>
<li class="chapter" data-level="2.1" data-path="settheory.html"><a href="settheory.html#random-experiments-events-and-sample-spaces"><i class="fa fa-check"></i><b>2.1</b> Random Experiments, Events and Sample Spaces</a></li>
<li class="chapter" data-level="2.2" data-path="settheory.html"><a href="settheory.html#some-definitions-from-set-theory"><i class="fa fa-check"></i><b>2.2</b> Some definitions from set theory</a></li>
<li class="chapter" data-level="2.3" data-path="settheory.html"><a href="settheory.html#the-venn-diagram"><i class="fa fa-check"></i><b>2.3</b> The Venn diagram</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="settheory.html"><a href="settheory.html#sample-space-and-events"><i class="fa fa-check"></i><b>2.3.1</b> Sample Space and Events</a></li>
<li class="chapter" data-level="2.3.2" data-path="settheory.html"><a href="settheory.html#exclusive-and-non-exclusive-events"><i class="fa fa-check"></i><b>2.3.2</b> Exclusive and Non-Exclusive Events</a></li>
<li class="chapter" data-level="2.3.3" data-path="settheory.html"><a href="settheory.html#union-and-intersection-of-events"><i class="fa fa-check"></i><b>2.3.3</b> Union and Intersection of Events</a></li>
<li class="chapter" data-level="2.3.4" data-path="settheory.html"><a href="settheory.html#complement"><i class="fa fa-check"></i><b>2.3.4</b> Complement</a></li>
<li class="chapter" data-level="2.3.5" data-path="settheory.html"><a href="settheory.html#some-properties-of-union-and-intersection"><i class="fa fa-check"></i><b>2.3.5</b> Some Properties of union and intersection</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="settheory.html"><a href="settheory.html#countable-and-uncountable-sets"><i class="fa fa-check"></i><b>2.4</b> Countable and Uncountable sets</a></li>
<li class="chapter" data-level="2.5" data-path="settheory.html"><a href="settheory.html#de-morgans-laws"><i class="fa fa-check"></i><b>2.5</b> De Morgan‚Äôs Laws</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="settheory.html"><a href="settheory.html#first-law"><i class="fa fa-check"></i><b>2.5.1</b> First Law</a></li>
<li class="chapter" data-level="2.5.2" data-path="settheory.html"><a href="settheory.html#second-law"><i class="fa fa-check"></i><b>2.5.2</b> Second Law</a></li>
<li class="chapter" data-level="2.5.3" data-path="settheory.html"><a href="settheory.html#de-morgans-theorem"><i class="fa fa-check"></i><b>2.5.3</b> De Morgan‚Äôs Theorem</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="settheory.html"><a href="settheory.html#probability-as-frequency"><i class="fa fa-check"></i><b>2.6</b> Probability as Frequency</a></li>
<li class="chapter" data-level="2.7" data-path="settheory.html"><a href="settheory.html#some-references"><i class="fa fa-check"></i><b>2.7</b> Some references</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="axioms.html"><a href="axioms.html"><i class="fa fa-check"></i><b>3</b> Probability Axioms</a>
<ul>
<li class="chapter" data-level="3.1" data-path="axioms.html"><a href="axioms.html#an-axiomatic-definition-of-probability"><i class="fa fa-check"></i><b>3.1</b> An Axiomatic Definition of Probability</a></li>
<li class="chapter" data-level="3.2" data-path="axioms.html"><a href="axioms.html#properties-of-pcdot"><i class="fa fa-check"></i><b>3.2</b> Properties of <span class="math inline">\(P(\cdot)\)</span></a></li>
<li class="chapter" data-level="3.3" data-path="axioms.html"><a href="axioms.html#examples-and-illustrations"><i class="fa fa-check"></i><b>3.3</b> Examples and Illustrations</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="axioms.html"><a href="axioms.html#flipping-coins"><i class="fa fa-check"></i><b>3.3.1</b> Flipping coins</a></li>
<li class="chapter" data-level="3.3.2" data-path="axioms.html"><a href="axioms.html#detecting-shoppers"><i class="fa fa-check"></i><b>3.3.2</b> Detecting shoppers</a></li>
<li class="chapter" data-level="3.3.3" data-path="axioms.html"><a href="axioms.html#de-morgans-law"><i class="fa fa-check"></i><b>3.3.3</b> De Morgan‚Äôs Law</a></li>
<li class="chapter" data-level="3.3.4" data-path="axioms.html"><a href="axioms.html#probability-union-and-complement"><i class="fa fa-check"></i><b>3.3.4</b> Probability, union, and complement</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="axioms.html"><a href="axioms.html#conditional-probability"><i class="fa fa-check"></i><b>3.4</b> Conditional probability</a></li>
<li class="chapter" data-level="3.5" data-path="axioms.html"><a href="axioms.html#independence"><i class="fa fa-check"></i><b>3.5</b> Independence</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="axioms.html"><a href="axioms.html#another-characterisation"><i class="fa fa-check"></i><b>3.5.1</b> Another characterisation</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="axioms.html"><a href="axioms.html#theorem-i-the-theorem-of-total-probabilities"><i class="fa fa-check"></i><b>3.6</b> Theorem I: The Theorem of Total Probabilities</a></li>
<li class="chapter" data-level="3.7" data-path="axioms.html"><a href="axioms.html#theorem-ii-bayes-theorem"><i class="fa fa-check"></i><b>3.7</b> Theorem II: Bayes‚Äô Theorem</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="axioms.html"><a href="axioms.html#guessing-in-a-multiple-choice-exam"><i class="fa fa-check"></i><b>3.7.1</b> Guessing in a multiple choice exam</a></li>
<li class="chapter" data-level="3.7.2" data-path="axioms.html"><a href="axioms.html#rent-car-maintenance"><i class="fa fa-check"></i><b>3.7.2</b> Rent car maintenance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="discreterv.html"><a href="discreterv.html"><i class="fa fa-check"></i><b>4</b> üîß Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="4.1" data-path="discreterv.html"><a href="discreterv.html#what-is-a-random-variable"><i class="fa fa-check"></i><b>4.1</b> What is a Random Variable?</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="discreterv.html"><a href="discreterv.html#formal-definition-of-a-random-variable"><i class="fa fa-check"></i><b>4.1.1</b> Formal definition of a random variable</a></li>
<li class="chapter" data-level="4.1.2" data-path="discreterv.html"><a href="discreterv.html#example-from-s-to-d-via-xcdot"><i class="fa fa-check"></i><b>4.1.2</b> Example: from <span class="math inline">\(S\)</span> to <span class="math inline">\(D\)</span>, via <span class="math inline">\(X(\cdot)\)</span></a></li>
<li class="chapter" data-level="4.1.3" data-path="discreterv.html"><a href="discreterv.html#an-example-from-gambling"><i class="fa fa-check"></i><b>4.1.3</b> An Example from gambling</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="discreterv.html"><a href="discreterv.html#discrete-random-variables"><i class="fa fa-check"></i><b>4.2</b> Discrete random variables</a></li>
<li class="chapter" data-level="4.3" data-path="discreterv.html"><a href="discreterv.html#cumulative-distribution-function"><i class="fa fa-check"></i><b>4.3</b> Cumulative Distribution Function</a></li>
<li class="chapter" data-level="4.4" data-path="discreterv.html"><a href="discreterv.html#distributional-summaries-for-discrete-random-variables"><i class="fa fa-check"></i><b>4.4</b> Distributional summaries for discrete random variables</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="discreterv.html"><a href="discreterv.html#properties"><i class="fa fa-check"></i><b>4.4.1</b> Properties</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="discreterv.html"><a href="discreterv.html#dependenceindependence"><i class="fa fa-check"></i><b>4.5</b> Dependence/Independence</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="discreterv.html"><a href="discreterv.html#more-important-properties"><i class="fa fa-check"></i><b>4.5.1</b> More important properties</a></li>
<li class="chapter" data-level="4.5.2" data-path="discreterv.html"><a href="discreterv.html#more-on-expectations"><i class="fa fa-check"></i><b>4.5.2</b> More on expectations</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="discreterv.html"><a href="discreterv.html#some-discrete-distributions-of-interest"><i class="fa fa-check"></i><b>4.6</b> Some discrete distributions of interest</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="discreterv.html"><a href="discreterv.html#discrete-uniform-distribution"><i class="fa fa-check"></i><b>4.6.1</b> Discrete uniform distribution</a></li>
<li class="chapter" data-level="4.6.2" data-path="discreterv.html"><a href="discreterv.html#bernoulli-trials"><i class="fa fa-check"></i><b>4.6.2</b> Bernoulli Trials</a></li>
<li class="chapter" data-level="4.6.3" data-path="discreterv.html"><a href="discreterv.html#the-binomial-distribution"><i class="fa fa-check"></i><b>4.6.3</b> The Binomial Distribution</a></li>
<li class="chapter" data-level="4.6.4" data-path="discreterv.html"><a href="discreterv.html#poisson-distribution"><i class="fa fa-check"></i><b>4.6.4</b> Poisson Distribution</a></li>
<li class="chapter" data-level="4.6.5" data-path="discreterv.html"><a href="discreterv.html#the-hypergeometric-distribution"><i class="fa fa-check"></i><b>4.6.5</b> The Hypergeometric Distribution</a></li>
<li class="chapter" data-level="4.6.6" data-path="discreterv.html"><a href="discreterv.html#the-negative-binomial-distribution"><i class="fa fa-check"></i><b>4.6.6</b> The Negative Binomial Distribution</a></li>
<li class="chapter" data-level="4.6.7" data-path="discreterv.html"><a href="discreterv.html#illustrations-4"><i class="fa fa-check"></i><b>4.6.7</b> Illustrations</a></li>
<li class="chapter" data-level="4.6.8" data-path="discreterv.html"><a href="discreterv.html#the-geometric-distribution"><i class="fa fa-check"></i><b>4.6.8</b> The Geometric Distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="continuousrv.html"><a href="continuousrv.html"><i class="fa fa-check"></i><b>5</b> üîß Continuous Random Variable</a>
<ul>
<li class="chapter" data-level="5.1" data-path="continuousrv.html"><a href="continuousrv.html#two-motivating-examples"><i class="fa fa-check"></i><b>5.1</b> Two Motivating Examples</a></li>
<li class="chapter" data-level="5.2" data-path="continuousrv.html"><a href="continuousrv.html#cumulative-distribution-function-cdf"><i class="fa fa-check"></i><b>5.2</b> Cumulative Distribution Function (CDF)</a></li>
<li class="chapter" data-level="5.3" data-path="continuousrv.html"><a href="continuousrv.html#distributional-summaries"><i class="fa fa-check"></i><b>5.3</b> Distributional Summaries</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="continuousrv.html"><a href="continuousrv.html#the-expectation"><i class="fa fa-check"></i><b>5.3.1</b> The Expectation</a></li>
<li class="chapter" data-level="5.3.2" data-path="continuousrv.html"><a href="continuousrv.html#the-variance"><i class="fa fa-check"></i><b>5.3.2</b> The Variance</a></li>
<li class="chapter" data-level="5.3.3" data-path="continuousrv.html"><a href="continuousrv.html#important-properties-of-expectations"><i class="fa fa-check"></i><b>5.3.3</b> Important properties of expectations</a></li>
<li class="chapter" data-level="5.3.4" data-path="continuousrv.html"><a href="continuousrv.html#mode-and-median"><i class="fa fa-check"></i><b>5.3.4</b> Mode and Median</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="continuousrv.html"><a href="continuousrv.html#some-important-continuous-distributions"><i class="fa fa-check"></i><b>5.4</b> Some Important Continuous Distributions</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="continuousrv.html"><a href="continuousrv.html#continuous-uniform-distribution"><i class="fa fa-check"></i><b>5.4.1</b> Continuous Uniform Distribution</a></li>
<li class="chapter" data-level="5.4.2" data-path="continuousrv.html"><a href="continuousrv.html#normal-gaussian-distribution"><i class="fa fa-check"></i><b>5.4.2</b> Normal (Gaussian) distribution</a></li>
<li class="chapter" data-level="5.4.3" data-path="continuousrv.html"><a href="continuousrv.html#the-chi-squared-distribution"><i class="fa fa-check"></i><b>5.4.3</b> The Chi-squared distribution</a></li>
<li class="chapter" data-level="5.4.4" data-path="continuousrv.html"><a href="continuousrv.html#the-student-t-distribution"><i class="fa fa-check"></i><b>5.4.4</b> The Student-t distribution</a></li>
<li class="chapter" data-level="5.4.5" data-path="continuousrv.html"><a href="continuousrv.html#the-f-distribution"><i class="fa fa-check"></i><b>5.4.5</b> The F distribution</a></li>
<li class="chapter" data-level="5.4.6" data-path="continuousrv.html"><a href="continuousrv.html#the-lognormal-distribution"><i class="fa fa-check"></i><b>5.4.6</b> The lognormal distribution</a></li>
<li class="chapter" data-level="5.4.7" data-path="continuousrv.html"><a href="continuousrv.html#exponential-distribution"><i class="fa fa-check"></i><b>5.4.7</b> Exponential distribution</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="continuousrv.html"><a href="continuousrv.html#transformation-of-variables"><i class="fa fa-check"></i><b>5.5</b> Transformation of variables</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="continuousrv.html"><a href="continuousrv.html#transformation-of-discrete-random-variables"><i class="fa fa-check"></i><b>5.5.1</b> Transformation of discrete random variables</a></li>
<li class="chapter" data-level="5.5.2" data-path="continuousrv.html"><a href="continuousrv.html#transformation-of-variables-using-the-cdf"><i class="fa fa-check"></i><b>5.5.2</b> Transformation of variables using the CDF</a></li>
<li class="chapter" data-level="5.5.3" data-path="continuousrv.html"><a href="continuousrv.html#function-1-to-1-and-monotone-decreasing"><i class="fa fa-check"></i><b>5.5.3</b> Function 1-to-1 and monotone decreasing</a></li>
<li class="chapter" data-level="5.5.4" data-path="continuousrv.html"><a href="continuousrv.html#transformation-of-continuous-rv-through-pdf"><i class="fa fa-check"></i><b>5.5.4</b> Transformation of continuous RV through pdf</a></li>
<li class="chapter" data-level="5.5.5" data-path="continuousrv.html"><a href="continuousrv.html#example-of-transformation-using-pdf"><i class="fa fa-check"></i><b>5.5.5</b> Example of transformation using pdf</a></li>
<li class="chapter" data-level="5.5.6" data-path="continuousrv.html"><a href="continuousrv.html#a-caveat"><i class="fa fa-check"></i><b>5.5.6</b> A caveat</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="continuousrv.html"><a href="continuousrv.html#the-big-picture"><i class="fa fa-check"></i><b>5.6</b> The big picture</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="limittheorems.html"><a href="limittheorems.html"><i class="fa fa-check"></i><b>6</b> üìù Limit Theorems</a>
<ul>
<li class="chapter" data-level="6.1" data-path="limittheorems.html"><a href="limittheorems.html#sequences-of-random-variables"><i class="fa fa-check"></i><b>6.1</b> Sequences of Random Variables</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="limittheorems.html"><a href="limittheorems.html#example-bernoulli-trials-and-their-sum"><i class="fa fa-check"></i><b>6.1.1</b> Example: Bernoulli Trials and their sum</a></li>
<li class="chapter" data-level="6.1.2" data-path="limittheorems.html"><a href="limittheorems.html#example-bernoulli-trials-and-limit-behaviour"><i class="fa fa-check"></i><b>6.1.2</b> Example: Bernoulli Trials and limit behaviour</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="limittheorems.html"><a href="limittheorems.html#convergence-in-probability-oversetprightarrow"><i class="fa fa-check"></i><b>6.2</b> Convergence in Probability (<span class="math inline">\(\overset{p}{\rightarrow }\)</span>)</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="limittheorems.html"><a href="limittheorems.html#operational-rules-for-oversetprightarrow"><i class="fa fa-check"></i><b>6.2.1</b> Operational Rules for <span class="math inline">\(\overset{p}{\rightarrow }\)</span></a></li>
<li class="chapter" data-level="6.2.2" data-path="limittheorems.html"><a href="limittheorems.html#convergence-of-sample-moments-as-a-motivation"><i class="fa fa-check"></i><b>6.2.2</b> Convergence of Sample Moments as a motivation‚Ä¶</a></li>
<li class="chapter" data-level="6.2.3" data-path="limittheorems.html"><a href="limittheorems.html#the-weak-law-of-large-numbers-wlln"><i class="fa fa-check"></i><b>6.2.3</b> The Weak Law of Large Numbers (WLLN)</a></li>
<li class="chapter" data-level="6.2.4" data-path="limittheorems.html"><a href="limittheorems.html#the-wlln-and-chebyshevs-inequality"><i class="fa fa-check"></i><b>6.2.4</b> The WLLN and Chebyshev‚Äôs Inequality</a></li>
<li class="chapter" data-level="6.2.5" data-path="limittheorems.html"><a href="limittheorems.html#chebyshevs-and-markovs-inequality"><i class="fa fa-check"></i><b>6.2.5</b> Chebyshev‚Äôs (and Markov‚Äôs) Inequality</a></li>
<li class="chapter" data-level="6.2.6" data-path="limittheorems.html"><a href="limittheorems.html#example-markovs-inequality"><i class="fa fa-check"></i><b>6.2.6</b> Example: Markov‚Äôs Inequality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html"><i class="fa fa-check"></i><b>7</b> üìù Bivariate Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="7.1" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#joint-probability-functions"><i class="fa fa-check"></i><b>7.1</b> Joint Probability Functions</a></li>
<li class="chapter" data-level="7.2" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#marginal-probability-mass-functions"><i class="fa fa-check"></i><b>7.2</b> Marginal probability (mass) functions</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#first-example"><i class="fa fa-check"></i><b>7.2.1</b> First Example</a></li>
<li class="chapter" data-level="7.2.2" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#empirical-example"><i class="fa fa-check"></i><b>7.2.2</b> Empirical Example</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#conditional-probability-mass-function"><i class="fa fa-check"></i><b>7.3</b> Conditional probability mass function</a></li>
<li class="chapter" data-level="7.4" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#independence-1"><i class="fa fa-check"></i><b>7.4</b> Independence</a></li>
<li class="chapter" data-level="7.5" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#expectations-for-jointly-distributed-discrete-rvs"><i class="fa fa-check"></i><b>7.5</b> Expectations for Jointly Distributed Discrete RVs</a></li>
<li class="chapter" data-level="7.6" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#iterated-expectations"><i class="fa fa-check"></i><b>7.6</b> Iterated Expectations</a></li>
<li class="chapter" data-level="7.7" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#expectations-for-jointly-distributed-discrete-rvs-1"><i class="fa fa-check"></i><b>7.7</b> Expectations for Jointly Distributed Discrete RVs</a></li>
<li class="chapter" data-level="7.8" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#some-properties-of-covariances"><i class="fa fa-check"></i><b>7.8</b> Some Properties of Covariances</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#a-remark"><i class="fa fa-check"></i><b>7.8.1</b> A remark</a></li>
<li class="chapter" data-level="7.8.2" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#an-important-property-of-correlation"><i class="fa fa-check"></i><b>7.8.2</b> An important property of correlation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="numericalmethods.html"><a href="numericalmethods.html"><i class="fa fa-check"></i><b>8</b> üìù Numerical Methods</a>
<ul>
<li class="chapter" data-level="8.1" data-path="numericalmethods.html"><a href="numericalmethods.html#introduction-to-simulation"><i class="fa fa-check"></i><b>8.1</b> Introduction to simulation</a></li>
<li class="chapter" data-level="8.2" data-path="numericalmethods.html"><a href="numericalmethods.html#simulation-procedure"><i class="fa fa-check"></i><b>8.2</b> Simulation procedure</a></li>
<li class="chapter" data-level="8.3" data-path="numericalmethods.html"><a href="numericalmethods.html#simulation-in-r"><i class="fa fa-check"></i><b>8.3</b> Simulation in R</a></li>
<li class="chapter" data-level="8.4" data-path="numericalmethods.html"><a href="numericalmethods.html#coin-tossing"><i class="fa fa-check"></i><b>8.4</b> Coin tossing</a></li>
<li class="chapter" data-level="8.5" data-path="numericalmethods.html"><a href="numericalmethods.html#summarizing"><i class="fa fa-check"></i><b>8.5</b> Summarizing</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="exercise-solutions.html"><a href="exercise-solutions.html"><i class="fa fa-check"></i><b>9</b> üìù Exercise Solutions</a>
<ul>
<li class="chapter" data-level="9.1" data-path="exercise-solutions.html"><a href="exercise-solutions.html#chapter-1"><i class="fa fa-check"></i><b>9.1</b> Chapter 1</a></li>
<li class="chapter" data-level="9.2" data-path="exercise-solutions.html"><a href="exercise-solutions.html#chapter-2"><i class="fa fa-check"></i><b>9.2</b> Chapter 2</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="exercise-solutions.html"><a href="exercise-solutions.html#exercise-2.1"><i class="fa fa-check"></i><b>9.2.1</b> Exercise 2.1</a></li>
<li class="chapter" data-level="9.2.2" data-path="exercise-solutions.html"><a href="exercise-solutions.html#exercise-2.2"><i class="fa fa-check"></i><b>9.2.2</b> Exercise 2.2</a></li>
<li class="chapter" data-level="9.2.3" data-path="exercise-solutions.html"><a href="exercise-solutions.html#exercise-2.3"><i class="fa fa-check"></i><b>9.2.3</b> Exercise 2.3</a></li>
<li class="chapter" data-level="9.2.4" data-path="exercise-solutions.html"><a href="exercise-solutions.html#exercise-2.4"><i class="fa fa-check"></i><b>9.2.4</b> Exercise 2.4</a></li>
<li class="chapter" data-level="9.2.5" data-path="exercise-solutions.html"><a href="exercise-solutions.html#exercise-2.5"><i class="fa fa-check"></i><b>9.2.5</b> Exercise 2.5</a></li>
<li class="chapter" data-level="9.2.6" data-path="exercise-solutions.html"><a href="exercise-solutions.html#exercise-2.6"><i class="fa fa-check"></i><b>9.2.6</b> Exercise 2.6</a></li>
<li class="chapter" data-level="9.2.7" data-path="exercise-solutions.html"><a href="exercise-solutions.html#exercise-2.7"><i class="fa fa-check"></i><b>9.2.7</b> Exercise 2.7</a></li>
<li class="chapter" data-level="9.2.8" data-path="exercise-solutions.html"><a href="exercise-solutions.html#exercise-2.8"><i class="fa fa-check"></i><b>9.2.8</b> Exercise 2.8</a></li>
<li class="chapter" data-level="9.2.9" data-path="exercise-solutions.html"><a href="exercise-solutions.html#exercise-2.8-1"><i class="fa fa-check"></i><b>9.2.9</b> Exercise 2.8</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="exercise-solutions.html"><a href="exercise-solutions.html#chapter-3"><i class="fa fa-check"></i><b>9.3</b> Chapter 3</a></li>
<li class="chapter" data-level="9.4" data-path="exercise-solutions.html"><a href="exercise-solutions.html#chapter-4"><i class="fa fa-check"></i><b>9.4</b> Chapter 4</a></li>
<li class="chapter" data-level="9.5" data-path="exercise-solutions.html"><a href="exercise-solutions.html#chapter-5"><i class="fa fa-check"></i><b>9.5</b> Chapter 5</a></li>
<li class="chapter" data-level="9.6" data-path="exercise-solutions.html"><a href="exercise-solutions.html#chapter-6"><i class="fa fa-check"></i><b>9.6</b> Chapter 6</a></li>
<li class="chapter" data-level="9.7" data-path="exercise-solutions.html"><a href="exercise-solutions.html#chapter-7"><i class="fa fa-check"></i><b>9.7</b> Chapter 7</a></li>
<li class="chapter" data-level="9.8" data-path="exercise-solutions.html"><a href="exercise-solutions.html#chapter-8"><i class="fa fa-check"></i><b>9.8</b> Chapter 8</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">üÉè Probability I</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="bivariatediscreterv" class="section level1" number="7">
<h1><span class="header-section-number">Chapter 7</span> üìù Bivariate Discrete Random Variables</h1>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-1"></span>
<img src="img/fun/EC_correlation.png" alt="'Correlation' by Enrico Chavez" width="218" />
<p class="caption">
Figure 7.1: ‚ÄòCorrelation‚Äô by Enrico Chavez
</p>
</div>
<!--  -->
<!--  -->
<!-- %% -->
<!--  -->
<!-- % -->
<!-- %%\subsection{Jointly distributed discrete random variables} -->
<!-- % -->
<!-- % -->
<!-- %% -->
<!-- %%% -->
<!-- % -->
<!-- %% -->
<!-- %## {Jointly distributed discrete random variables} -->
<!-- %% -->
<!-- %```{example} -->
<!-- % -->
<!-- %- Two production lines manufacture a certain type of item. -->
<!-- % -->
<!-- %- Suppose that the capacity (on any given day) is 5 items for \emph{Line -->
<!-- %I }and 3 items for \emph{Line II}. -->
<!-- % -->
<!-- %- Assume that the number of items actually produced by either production -->
<!-- %line is a random variable. -->
<!-- % -->
<!-- %- Let $(X,Y)$ represent the 2-dimensional random variable yielding the -->
<!-- %number of items produced by \emph{Line I} and \emph{Line II}, respectively. -->
<!-- % -->
<!-- %- The joint probability (mass) function is  -->
<!-- %$$ -->
<!-- %\Pr(\{X=x \quad \text{and} \quad Y=y\}) -->
<!-- %$$ -->
<!-- %for all possible values $x$ and $y$ -->
<!-- % -->
<!-- %``` -->
<!-- %% -->
<!-- % -->
<!-- % -->
<!-- % -->
<!-- %## {Jointly distributed discrete random variables} -->
<!-- %```{example}[cont'd] -->
<!-- %\begin{tabular}{|cc||c|c|c|c|c|c||c|} -->
<!-- %\hline -->
<!-- %& $x$ & $0$ & $1$ & $2$ & $3$ & $4$ & $5$ & $\Pr \left\{ Y=y\right\} $ \\ -->
<!-- %$y$ &  &  &  &  &  &  &  &  \\ \hline\hline -->
<!-- %$0$ &  & $0$ & $0.01$ & $0.03$ & $0.05$ & $0.07$ & $0.09$ & $0.25$ \\ \hline -->
<!-- %$1$ &  & $0.01$ & $0.02$ & $0.04$ & $0.05$ & $0.06$ & $0.08$ & $0.26$ \\ -->
<!-- %\hline -->
<!-- %$2$ &  & $0.01$ & $0.03$ & $0.05$ & $0.05$ & $0.05$ & $0.06$ & $0.25$ \\ -->
<!-- %\hline -->
<!-- %$3$ &  & $0.01$ & $0.02$ & $0.04$ & $0.06$ & $0.06$ & $0.05$ & $0.24$ \\ -->
<!-- %\hline\hline -->
<!-- %$\Pr \left\{ X=x\right\} $ &  & $0.03$ & $0.08$ & $0.16$ & $0.21$ & $0.24$ & -->
<!-- %$0.28$ & $1$ \\ \hline -->
<!-- %\end{tabular} -->
<!-- %``` -->
<!-- %% -->
<div id="joint-probability-functions" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Joint Probability Functions</h2>
<ul>
<li><p>Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be a pair of discrete random variables</p></li>
<li><p>Their  (joint
PMF) expresses the probability that simultaneously <span class="math inline">\(X\)</span> takes on the specific
value <span class="math inline">\(x\)</span> and <span class="math inline">\(Y\)</span> takes on the specific value <span class="math inline">\(y\)</span>.</p></li>
<li><p>It is denoted by
<span class="math display">\[\begin{equation*}
p_{X,Y}\left( x,y\right) =\Pr (\left\{ X=x\cap Y=y\right\})
\end{equation*}\]</span>
thought of as a function of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</p></li>
<li><p>The joint PMF has two essential properties:</p></li>
<li><p><span class="math inline">\(p_{X,Y}\left( x,y\right) \geq 0\)</span> for all possible pairs $(
x,y) $ (its value is always non-negative)</p></li>
<li><p><span class="math inline">\(\sum_{x}\sum_{y}\Pr ( \left\{ X=x\cap Y=y\right\}) =1\)</span> (its sum over all
combinations of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> values is equal to one)</p></li>
</ul>
</div>
<div id="marginal-probability-mass-functions" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Marginal probability (mass) functions</h2>

<div class="definition">
<p><span id="def:unnamed-chunk-2" class="definition"><strong>Definition 7.1  </strong></span>The probability (mass) function of the  random variable
<span class="math inline">\(X\)</span> is called its marginal probability (mass) function. It is obtained by summing the joint probabilities relating to pairs <span class="math inline">\(% (X,Y)\)</span> over all possible values of <span class="math inline">\(Y\)</span>:%
<span class="math display">\[\begin{equation*}
p_{X}(x)=\sum_{y}p_{X,Y}(x,y).
\end{equation*}\]</span></p>
Similarly, the probability (mass) function of the 
random variable <span class="math inline">\(Y\)</span> is called its marginal probability (mass) function. It is obtained by summing the joint probabilities relating to pairs <span class="math inline">\(% (X,Y)\)</span> overall possible values of <span class="math inline">\(X\)</span>:%
<span class="math display">\[\begin{equation*}
p_{Y}(y)=\sum_{x}p_{X,Y}(x,y).
\end{equation*}\]</span>
</div>
<div id="first-example" class="section level3" number="7.2.1">
<h3><span class="header-section-number">7.2.1</span> First Example</h3>

<div class="example">
<p><span id="exm:unnamed-chunk-3" class="example"><strong>Example 7.1  </strong></span>
[caplets: this probability course is giving me headache]</p>
<ul>
<li><p>Two caplets are selected at random from a bottle containing three
aspirins, two sedatives and two placebo caplets. We are assuming that the caplets are well mixed and that each has an
equal chance of being selected.</p></li>
<li><p>Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> denote, respectively, the numbers of aspirin caplets,
and the number of sedative caplets, included among the two caplets drawn
from the bottle.
%
%- We want to find the probabilities associated with all possible values
%of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.
%
%- All the possible pairs of <span class="math inline">\((X,Y)\)</span> are <span class="math inline">\((0,0)\)</span>,<span class="math inline">\((1,0)\)</span>, <span class="math inline">\((0,1)\)</span>, <span class="math inline">\((1,1)\)</span>%
%, <span class="math inline">\((2,0)\)</span>, and <span class="math inline">\((0,2)\)</span>.</p></li>
</ul>
</div>
<!-- % -->
<!--  -->
<!-- % -->
<!-- %## {First Example} -->
<!-- % -->
<!-- %%```{example}[cont'd] -->
<!-- % -->
<!-- %- To work out each of these probabilties, we use combinations. -->
<!-- % -->
<!-- % -->
<!-- %- e.g., the outcome $(1,1)$ corresponds to choosing only one asprin -->
<!-- %caplet and only one sedative caplet. -->
<!-- % -->
<!-- % -->
<!-- %- But that one asprin caplet could be any one of the three available in -->
<!-- %the jar, -->
<!-- % -->
<!-- %- and that one sedative caplet could be either one of the two available -->
<!-- %in the jar. -->
<!-- % -->
<!-- %- So the number of possible combinations that satisfy $\left( x,y\right) -->
<!-- %=(1,1)$ are% -->
<!-- %\begin{eqnarray*} -->
<!-- %\underset{\text{\# asprin}}{\underbrace{\left(  -->
<!-- %\begin{array}{c} -->
<!-- %3 \\  -->
<!-- %1% -->
<!-- %\end{array}% -->
<!-- %\right) }}\times \underset{\text{\# sedative}}{\underbrace{\left(  -->
<!-- %\begin{array}{c} -->
<!-- %2 \\  -->
<!-- %1% -->
<!-- %\end{array}% -->
<!-- %\right) }}\times \underset{\text{\# placebo}}{\underbrace{\left(  -->
<!-- %\begin{array}{c} -->
<!-- %2 \\  -->
<!-- %0% -->
<!-- %\end{array}% -->
<!-- %\right) }} &=&\frac{3!}{1!2!}\times \frac{2!}{1!1!}\times \frac{2!}{2!0!} \\ -->
<!-- %&=&3\times 2\times 1=6 -->
<!-- %\end{eqnarray*} -->
<!-- % -->
<!-- % -->
<!-- %- We can work out the number of possible combinations for the remaining $% -->
<!-- %\left( x,y\right) $ pairs similarly. -->
<!-- % -->
<!-- % -->
<!-- %%``` -->
<!-- % -->
<!-- % -->
<!-- %% -->
<!--  -->
<!-- %% -->
<!-- %% -->
<!-- %% -->
<!-- %% -->
<!--  -->
<!-- % -->
<!-- %## {First Example (Discrete)} -->
<!-- % -->
<!-- %The \emph{probability} can be tabulated as -->
<!-- % -->
<!-- %\begin{center} -->
<!-- %\begin{tabular}{|c||c||c||c|} -->
<!-- %\hline -->
<!-- %${\small (x,y)}$ & {\small event drawn} & {\small combinations} & $\Pr -->
<!-- %\left\{ \left( X,Y\right) =\left( x,y\right) \right\} $ \\ \hline\hline -->
<!-- %${\small (0,0)}$ & {\small 2 placebos} & ${\small 1}$ & ${\small 1/21}$ \\  -->
<!-- %\hline -->
<!-- %${\small (1,0)}$ & {\small 1 asprin,1 placebo} & ${\small 6}$ & ${\small 6/21% -->
<!-- %}$ \\ \hline -->
<!-- %${\small (0,1)}$ & {\small 1 sedative, 1 placebo} & ${\small 4}$ & ${\small % -->
<!-- %4/21}$ \\ \hline -->
<!-- %${\small (1,1)}$ & {\small 1 asprin, 1 placebo} & ${\small 6}$ & ${\small % -->
<!-- %6/21}$ \\ \hline -->
<!-- %${\small (2,0)}$ & {\small 2 asprin} & ${\small 3}$ & ${\small 3/21}$ \\  -->
<!-- %\hline -->
<!-- %${\small (0,2)}$ & {\small 2 sedatives} & ${\small 1}$ & ${\small 1/21}$ \\  -->
<!-- %\hline\hline -->
<!-- %{\small Total} &  & ${\small 21}$ & ${\small 1}$ \\ \hline -->
<!-- %\end{tabular} -->
<!-- %\end{center} -->
<!-- % -->

<div class="example">
<p><span id="exm:unnamed-chunk-4" class="example"><strong>Example 7.2  </strong></span>
[contd]</p>
<p>Tabulating the  probabilities as follows,
we can easily work out the 
probabilities</p>
</div>
<!-- % -->
<!-- %- Note that the expected value for $X$ and $Y$ are, respectively, -->
<!-- % -->
<!-- % -->
<!-- %- $E\left( X\right) =0\times 6/21+1\times 12/21+2\times 3/21=18/21=6/7$ -->
<!-- % -->
<!-- %- $E\left( Y\right) =0\times 10/21+1\times 10/21+2\times 1/21=12/21=4/7$ -->
<!-- % -->
<!-- % -->
</div>
<div id="empirical-example" class="section level3" number="7.2.2">
<h3><span class="header-section-number">7.2.2</span> Empirical Example</h3>

<div class="example">
<p><span id="exm:unnamed-chunk-5" class="example"><strong>Example 7.3  </strong></span></p>
<ul>
<li><p>Two production lines manufacture a certain type of item.</p></li>
<li><p>Suppose that the capacity (on any given day) is 5 items for and 3 items for .</p></li>
<li><p>Assume that the number of items actually produced by either production
line varies from one day to the next.</p></li>
<li><p>Let <span class="math inline">\((X,Y)\)</span> represent the 2-dimensional random variable yielding the
number of items produced by  and , respectively,
on any one day.</p></li>
<li><p>In practical applications of this type the joint probability (mass)
function <span class="math inline">\(\Pr(\{X=x\cap Y=y\})\)</span> is unknown more often than not!</p></li>
</ul>
</div>

<div class="example">
<p><span id="exm:unnamed-chunk-6" class="example"><strong>Example 7.4  </strong></span>
- The joint probability (mass) function <span class="math inline">\(\Pr(\{X=x\cap Y=y\})\)</span> for all possible values of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> can be approximated however.</p>
<ul>
<li>By the observing the long-run relative frequency with which different numbers of items are actually produced by either production line.</li>
</ul>
<ul>
<li>e.g.¬†<span class="math inline">\(\Pr(\{X=5\cap Y=0\})\approx 0.09=\frac{#\{X=5\cap Y=0\}\text{days}}{#\text{days}}\)</span>
</div></li>
</ul>
</div>
</div>
<div id="conditional-probability-mass-function" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Conditional probability mass function</h2>
<p>Recall that the  probability mass function of the random variable <span class="math inline">\(Y\)</span>,  that the random variable <span class="math inline">\(X\)</span> takes the
value <span class="math inline">\(x\)</span>, is given by%
<span class="math display">\[\begin{equation*}
p_{Y|X}\left( y|x\right) =\frac{\Pr \left\{ X=x\cap Y=y\right\} }{%
P_{X}\left( X=x\right) }
\end{equation*}\]</span></p>
<p>Note this is a probability mass function for <span class="math inline">\(y,\)</span> with <span class="math inline">\(x\)</span> viewed as
fixed. Similarly,</p>

<div class="definition">
<span id="def:unnamed-chunk-7" class="definition"><strong>Definition 7.2  </strong></span>The  probability mass function of the
random variable <span class="math inline">\(X\)</span>,  that the random variable $%
Y $ takes the value <span class="math inline">\(y\)</span>, is given by%
<span class="math display">\[\begin{equation*}
p_{X|Y}\left( x|y\right) =\frac{\Pr \left\{ X=x\cap Y=y\right\} }{%
P_{Y}\left( Y=y\right) }
\end{equation*}\]</span>
</div>
<p>Note this is a probability mass function for <span class="math inline">\(x,\)</span> with <span class="math inline">\(y\)</span> viewed as
fixed.</p>
<!-- % -->
<!-- %## {Conditional density functions} -->
<!-- % -->
<!-- % -->
<!-- %- The \emph{conditional} (probability) density function of the random -->
<!-- %variable $Y$, given that the \emph{continuous }random variable $X$ takes the -->
<!-- %value $x$, is given by% -->
<!-- %\begin{equation*} -->
<!-- %f_{Y|X}\left( y|x\right) =\frac{f_{X,Y}\left( x,y\right) }{f_{X}\left( -->
<!-- %x\right) } -->
<!-- %\end{equation*} -->
<!-- % -->
<!-- % -->
<!-- %- for every value of $y.$ Note this is a pdf for $y$, with $x$ viewed as -->
<!-- %fixed.\  -->
<!-- % -->
<!-- % -->
<!-- %- Similarly, the \emph{conditional} (probability) density function of -->
<!-- %the random variable $X$, given that the \emph{continuous }random variable $Y$ -->
<!-- %takes the value $y$, is given by% -->
<!-- %\begin{equation*} -->
<!-- %f_{X|Y}\left( x|y\right) =\frac{f_{X,Y}\left( x,y\right) }{f_{Y}\left( -->
<!-- %y\right) } -->
<!-- %\end{equation*} -->
<!-- % -->
<!-- % -->
<!-- %- for every value of $x$ \ Note this is a pdf for $x$, with $y$ viewed -->
<!-- %as fixed. -->
<!-- % -->
<!-- % -->
<!-- % -->
<!-- % -->
<!-- % -->
</div>
<div id="independence-1" class="section level2" number="7.4">
<h2><span class="header-section-number">7.4</span> Independence</h2>
<ul>
<li><p>Two random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are  if
<span class="math display">\[\begin{eqnarray*}
p_{X,Y}(x,y) &amp;=&amp;p_{X}(x)p_{Y}(y)\qquad \qquad \text{(discrete)} \\
%f_{X,Y}(x,y) &amp;=&amp;f_{X}(x)f_{Y}(y)\qquad \qquad \text{(continuous)}
\end{eqnarray*}\]</span>
for  values of <span class="math inline">\(x\)</span> and <span class="math inline">\(y.\)</span></p></li>
<li><p>Note that independence also implies that
<span class="math display">\[\begin{eqnarray*}
p_{X|Y}(x|y) &amp;=&amp;p_{X}(x)\text{ and }p_{Y|X}(y|x)=p_{Y}(y)\qquad \text{%
(discrete)} \\
%f_{X|Y}(x|y) &amp;=&amp;f_{X}(x)\text{ and }f_{Y|X}(y|x)=f_{Y}(y)\qquad \text{%
%(continuous)}
\end{eqnarray*}\]</span></p></li>
</ul>
<p>for  values of <span class="math inline">\(x\)</span> and <span class="math inline">\(y.\)</span></p>
</div>
<div id="expectations-for-jointly-distributed-discrete-rvs" class="section level2" number="7.5">
<h2><span class="header-section-number">7.5</span> Expectations for Jointly Distributed Discrete RVs</h2>

<div class="example">
<span id="exm:unnamed-chunk-8" class="example"><strong>Example 7.5  </strong></span>
</div>

<div class="example">
<span id="exm:unnamed-chunk-9" class="example"><strong>Example 7.6  </strong></span>
</div>

<div class="definition">
<span id="def:unnamed-chunk-10" class="definition"><strong>Definition 7.3  </strong></span>Let <span class="math inline">\(h(x,y)\)</span> be a function of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.
We define the  of $h( X,Y) $ as%
<span class="math display">\[\begin{equation*}
E\left[ h\left( X,Y\right) \right] =\sum_{y}\sum_{x}h\left( x,y\right)
p_{X,Y}\left( x,y\right)
\end{equation*}\]</span>
</div>

<div class="example">
<span id="exm:unnamed-chunk-11" class="example"><strong>Example 7.7  </strong></span>
</div>

<div class="definition">
<p><span id="def:unnamed-chunk-12" class="definition"><strong>Definition 7.4  </strong></span>The of $h( X,Y) $
 <span class="math inline">\(Y=y\)</span> is defined as%
<span class="math display">\[\begin{equation*}
E\left[ h\left( X,Y\right) |y\right] =\sum_{x}h\left( x,y\right)
p_{X|Y}\left( x|y\right).
\end{equation*}\]</span></p>
The of $h( X,Y) $
 <span class="math inline">\(X=x\)</span> is defined as%
<span class="math display">\[\begin{equation*}
E\left[ h\left( X,Y\right) |x\right] =\sum_{y}h\left( x,y\right)
p_{Y|X}\left( y|x\right).
\end{equation*}\]</span>
</div>

<div class="example">
<span id="exm:unnamed-chunk-13" class="example"><strong>Example 7.8  </strong></span>
[continuing the example at page 10]
</div>
<!-- % -->
<!-- %## {Expectations for Jointly Distributed Continuous RVs} -->
<!-- % -->
<!-- % -->
<!-- %- Let $h(x,y)$ be a function of $x$ and $y$ -->
<!-- % -->
<!-- %- We define the \textbf{expected value} of $h\left( X,Y\right) $ as% -->
<!-- %\begin{equation*} -->
<!-- %E\left[ h\left( X,Y\right) \right] =\int_{y}\int_{x}h\left( x,y\right) -->
<!-- %f_{X,Y}\left( x,y\right) dxdy -->
<!-- %\end{equation*} -->
<!-- % -->
<!-- %- Further, the \textbf{conditional expectation }of $h\left( X,Y\right) $  -->
<!-- %\emph{given} $Y=y$ is defined as% -->
<!-- %\begin{equation*} -->
<!-- %E\left[ h\left( X,Y\right) |Y=y\right] =\int_{x}h\left( x,y\right) -->
<!-- %f_{X|Y}\left( x|y\right) dx -->
<!-- %\end{equation*} -->
<!-- % -->
<!-- %- And, the \textbf{conditional expectation }of $h\left( X,Y\right) $  -->
<!-- %\emph{given} $X=x$ is defined as% -->
<!-- %\begin{equation*} -->
<!-- %E\left[ h\left( X,Y\right) |X=x\right] =\int_{y}h\left( x,y\right) -->
<!-- %f_{Y|X}\left( y|x\right) dy -->
<!-- %\end{equation*} -->
<!-- % -->
<!-- % -->
<!-- % -->
<!-- % -->
<!-- %% -->
</div>
<div id="iterated-expectations" class="section level2" number="7.6">
<h2><span class="header-section-number">7.6</span> Iterated Expectations</h2>

<div class="definition">
<span id="def:unnamed-chunk-14" class="definition"><strong>Definition 7.5  </strong></span>The  is often stated in the
form
<span class="math display">\[\begin{equation*}
E[h(X,Y)]=E[E[h(X,Y)|Y]]=E[E[h(X,Y)|X]]\,. 
\end{equation*}\]</span>
</div>
<ul>
<li><p>This notation emphasises that whenever we write down <span class="math inline">\(E[\cdot]\)</span> for an expectation we are taking that expectation with respect to the distribution implicit in the formulation of the argument.</p></li>
<li><p>The above formula is perhaps more easily understood using the more
explicit notation<br />
<span class="math display">\[\begin{equation*}
E_{(X,Y)}[h(X,Y)]=E_{(Y)}[E_{(X|Y)}[h(X,Y)]]=E_{(X)}[E_{(Y|X)}[h(X,Y)]]\,. 
\end{equation*}\]</span></p></li>
<li><p>The latter notation makes it clear what distribution is being used to evaluate the expectation, the joint, the marginal or the conditional.</p></li>
</ul>
</div>
<div id="expectations-for-jointly-distributed-discrete-rvs-1" class="section level2" number="7.7">
<h2><span class="header-section-number">7.7</span> Expectations for Jointly Distributed Discrete RVs</h2>

<div class="definition">
<span id="def:unnamed-chunk-15" class="definition"><strong>Definition 7.6  </strong></span>Let <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> be two discrete random variables.
The  between <span class="math inline">\(X\)</span> and<span class="math inline">\(Y\)</span> is given by$
E$ when
<span class="math display">\[\begin{equation*}
h\left(X,Y\right) =
\left(X-E\left[ X\right] \right) \left( Y-E\left[ Y\right] \right),
\end{equation*}\]</span>
i.e.¬†<span class="math inline">\(Cov\left(X,Y\right) =E\left[ \left(X-E\left[ X\right] \right) \left(Y-E\left[ Y\right] \right) \right]\)</span>
</div>
<p>Alternative formula for <span class="math inline">\(Cov(X,Y)\)</span> is
<span class="math display">\[\begin{equation}
\boxed{Cov\left( X,Y\right) =E\left[ XY\right] -E\left[ X\right] E\left[ Y\right]\ .} \label{Cov}
\end{equation}\]</span></p>
<p>So, to compute the covariance from a table describing the joint behaviour of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, you have to:</p>
<p>See example on page 13 for an illustrative computation.</p>
</div>
<div id="some-properties-of-covariances" class="section level2" number="7.8">
<h2><span class="header-section-number">7.8</span> Some Properties of Covariances</h2>
<ul>
<li><p>The Cauchy-Schwartz Inequality states
<span class="math display">\[(E\left[ XY\right])^2\leq E\left[ X^2\right]E\left[ Y^2\right],\]</span>
with equality if, and only if, <span class="math inline">\(\Pr(Y=cX)=1\)</span> for some constant <span class="math inline">\(c\)</span>.</p></li>
<li><p>Let <span class="math inline">\(h(a)=E[(Y-aX)^2]\)</span> where <span class="math inline">\(a\)</span> is any number. Then <span class="math display">\[0\leq h(a)=E[(Y-aX)^2]=E[X^2]a^2-2E[XY]a+E[Y^2]\,.\]</span></p></li>
</ul>
<p>This is a quadratic in <span class="math inline">\(a\)</span>, and</p>
<ul>
<li>if <span class="math inline">\(h(a)&gt;0\)</span> the roots are real and <span class="math inline">\(4(E[XY])^2-4E[X^2]E[Y^2]&lt;0\)</span>,</li>
<li>if <span class="math inline">\(h(a)=0\)</span> for some <span class="math inline">\(a=c\)</span> then <span class="math inline">\(E[(Y-cX)^2]=0\)</span>, which implies that <span class="math inline">\(\Pr(Y-cX=0)=1\)</span>.</li>
</ul>

<div class="remark">
 <span class="remark"><em>Remark. </em></span>  If two random variables are independent, their covariance is equal to
zero. Note that the converse is not necessarily true: a zero covariance
between two random variables does not imply that the variables are
independent. This asymmetry follows because 
</div>

<div class="example">
<span id="exm:unnamed-chunk-17" class="example"><strong>Example 7.9  </strong></span>
Let us consider two discrete random variable <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, such that <span class="math display">\[P(\{X=0\})=P(\{X=1\})=P(\{X=-1\})=\frac{1}{3},\]</span>
while <span class="math inline">\(Y=0\)</span> if <span class="math inline">\(X\neq 0\)</span> and <span class="math inline">\(Y=1\)</span>, if <span class="math inline">\(X=0\)</span>. So we have <span class="math inline">\(E[X]=0\)</span> and <span class="math inline">\(XY=0\)</span>. This implies
<span class="math display">\[Cov(X,Y) = E[XY] -E[X]E[Y] =0,\]</span>
although <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are NOT independent: they are related in a nonlinear way.
</div>
<p>Building on this remark, we have <span class="math inline">\(Cov(X,Y)&gt;0\)</span> if</p>
<ul>
<li><p>large values of <span class="math inline">\(X\)</span> tend to be associated with large
values of <span class="math inline">\(Y\)</span></p></li>
<li><p>small values of <span class="math inline">\(X\)</span> tend to be associated with small
values of <span class="math inline">\(Y\)</span></p></li>
<li><p><span class="math inline">\(Cov(X,Y)&lt;0\)</span> if</p></li>
<li><p>large values of <span class="math inline">\(X\)</span> tend to be  associated with  values of <span class="math inline">\(Y\)</span></p></li>
<li><p>small values of <span class="math inline">\(X\)</span> tend to be  associated with  values of <span class="math inline">\(Y\)</span></p></li>
<li><p>When <span class="math inline">\(Cov(X,Y)=0\)</span>, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are said to be uncorrelated.</p></li>
</ul>
<p>%</p>
<ul>
<li>If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are two random variables (either discrete or continuous) with <span class="math inline">\(Cov(X,Y) \neq 0\)</span>, then:
<span class="math display">\[\begin{equation}
Var(X + Y) =  Var(X) + Var(Y) + 2 Cov(X,Y) \label{FullVar}
\end{equation}\]</span></li>
</ul>
<p>, where we read that in the case of independent random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>
we have
<span class="math display">\[
Var(X + Y) =  Var(X) + Var(Y),
\]</span>
which trivially follows from ()‚Äîindeed, for independent random variables, <span class="math inline">\(Cov(X,Y)\equiv 0\)</span>.</p>
<ul>
<li>The covariance depends upon the unit of measurement.</li>
</ul>
<div id="a-remark" class="section level3" number="7.8.1">
<h3><span class="header-section-number">7.8.1</span> A remark</h3>
<ul>
<li>If we scale <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, the covariance changes: For <span class="math inline">\(a,b&gt;0\)</span>%
<span class="math display">\[\begin{equation*}
Cov\left( aX,bY\right) =abCov\left( X,Y\right)
\end{equation*}\]</span></li>
</ul>
<p>Thus, we introduce the between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is
<span class="math display">\[\begin{equation*}
corr\left( X,Y\right) =\frac{Cov\left( X,Y\right) }{\sqrt{Var\left( X\right)
Var\left( Y\right) }}
\end{equation*}\]</span></p>
<p>which depend upon the unit of measurement.</p>
<!-- % -->
<!-- % -->
<!-- %- Proof: For $a,b>0$% -->
<!-- %\begin{eqnarray*} -->
<!-- %corr\left( aX,bY\right)  &=&% -->
<!-- %%TCIMACRO{\TeXButton{Pause}{\pause}}% -->
<!-- % -->
<!-- %\pause% -->
<!-- %\frac{Cov\left( aX,bY\right) }{\sqrt{Var\left( aX\right) Var\left( bY\right) -->
<!-- %}}\medskip -->
<!-- %%TCIMACRO{\TeXButton{Pause}{\pause} }% -->
<!-- % -->
<!-- %\pause -->
<!-- %\\ -->
<!-- %&=&\frac{abCov\left( X,Y\right) }{\sqrt{a^{2}Var\left( X\right) -->
<!-- %b^{2}Var\left( Y\right) }}\medskip -->
<!-- %%TCIMACRO{\TeXButton{Pause}{\pause} }% -->
<!-- % -->
<!-- %\pause -->
<!-- %\\ -->
<!-- %&=&\frac{abCov\left( X,Y\right) }{ab\sqrt{Var\left( X\right) Var\left( -->
<!-- %Y\right) }}\medskip -->
<!-- %%TCIMACRO{\TeXButton{Pause}{\pause} }% -->
<!-- % -->
<!-- %\pause -->
<!-- %\\ -->
<!-- %&=&Corr\left( X,Y\right) \medskip -->
<!-- %%TCIMACRO{\TeXButton{Pause}{\pause}}% -->
<!-- % -->
<!-- %\pause% -->
<!-- %\end{eqnarray*} -->
<!-- % -->
</div>
<div id="an-important-property-of-correlation" class="section level3" number="7.8.2">
<h3><span class="header-section-number">7.8.2</span> An important property of correlation</h3>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> The Cauchy-Schwartz Inequality implies that
<span class="math display">\[\begin{equation*}
-1\leq corr\left( X,Y\right) \leq 1
\end{equation*}\]</span>
</div>
<p>The correlation is typically denoted by the Greek letter <span class="math inline">\(\rho\)</span>, so we have
<span class="math display">\[\rho(X,Y)= corr\left( X,Y\right).\]</span></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="limittheorems.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="numericalmethods.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/07-bivariate_discrete_rv.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
