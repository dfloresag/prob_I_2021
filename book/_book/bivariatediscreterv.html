<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 7 📝 Bivariate Discrete Random Variables | 🃏 Probability I</title>
<meta name="author" content="Dr. Daniel Flores Agreda (based on the Lecture by Prof. Davide La Vecchia)">
<meta name="description" content="Figure 7.1: ‘Correlation’ by Enrico Chavez                               7.1 Joint Probability Functions The joint PMF has two essential properties: The value of the Joint PMF is always...">
<meta name="generator" content="bookdown 0.24 with bs4_book()">
<meta property="og:title" content="Chapter 7 📝 Bivariate Discrete Random Variables | 🃏 Probability I">
<meta property="og:type" content="book">
<meta property="og:description" content="Figure 7.1: ‘Correlation’ by Enrico Chavez                               7.1 Joint Probability Functions The joint PMF has two essential properties: The value of the Joint PMF is always...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 7 📝 Bivariate Discrete Random Variables | 🃏 Probability I">
<meta name="twitter:description" content="Figure 7.1: ‘Correlation’ by Enrico Chavez                               7.1 Joint Probability Functions The joint PMF has two essential properties: The value of the Joint PMF is always...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.11/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="Course Notes">🃏 Probability I</a>:
        <small class="text-muted">Course Notes</small>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">About this lecture</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="settheory.html"><span class="header-section-number">2</span> Elements of Set Theory for Probability</a></li>
<li><a class="" href="axioms.html"><span class="header-section-number">3</span> Probability Axioms</a></li>
<li><a class="" href="discreterv.html"><span class="header-section-number">4</span> 🔧 Discrete Random Variables</a></li>
<li><a class="" href="continuousrv.html"><span class="header-section-number">5</span> 🔧 Continuous Random Variable</a></li>
<li><a class="" href="limittheorems.html"><span class="header-section-number">6</span> 📝 Limit Theorems</a></li>
<li><a class="active" href="bivariatediscreterv.html"><span class="header-section-number">7</span> 📝 Bivariate Discrete Random Variables</a></li>
<li><a class="" href="numericalmethods.html"><span class="header-section-number">8</span> 📝 Numerical Methods</a></li>
<li><a class="" href="exercise-solutions.html"><span class="header-section-number">9</span> 📝 Exercise Solutions</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="bivariatediscreterv" class="section level1" number="7">
<h1>
<span class="header-section-number">7</span> 📝 Bivariate Discrete Random Variables<a class="anchor" aria-label="anchor" href="#bivariatediscreterv"><i class="fas fa-link"></i></a>
</h1>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-201"></span>
<img src="img/fun/EC_correlation.png" alt="'Correlation' by Enrico Chavez" width="218"><p class="caption">
Figure 7.1: ‘Correlation’ by Enrico Chavez
</p>
</div>
<!--  -->
<!--  -->
<!-- %% -->
<!--  -->
<!-- % -->
<!-- %%\subsection{Jointly distributed discrete random variables} -->
<!-- % -->
<!-- % -->
<!-- %% -->
<!-- %%% -->
<!-- % -->
<!-- %% -->
<!-- %## {Jointly distributed discrete random variables} -->
<!-- %% -->
<!-- %```{example} -->
<!-- % -->
<!-- %- Two production lines manufacture a certain type of item. -->
<!-- % -->
<!-- %- Suppose that the capacity (on any given day) is 5 items for \emph{Line -->
<!-- %I }and 3 items for \emph{Line II}. -->
<!-- % -->
<!-- %- Assume that the number of items actually produced by either production -->
<!-- %line is a random variable. -->
<!-- % -->
<!-- %- Let $(X,Y)$ represent the 2-dimensional random variable yielding the -->
<!-- %number of items produced by \emph{Line I} and \emph{Line II}, respectively. -->
<!-- % -->
<!-- %- The joint probability (mass) function is  -->
<!-- %$$ -->
<!-- %\Pr(\{X=x \quad \text{and} \quad Y=y\}) -->
<!-- %$$ -->
<!-- %for all possible values $x$ and $y$ -->
<!-- % -->
<!-- %``` -->
<!-- %% -->
<!-- % -->
<!-- % -->
<!-- % -->
<!-- %## {Jointly distributed discrete random variables} -->
<!-- %```{example}[cont'd] -->
<!-- %\begin{tabular}{|cc||c|c|c|c|c|c||c|} -->
<!-- %\hline -->
<!-- %& $x$ & $0$ & $1$ & $2$ & $3$ & $4$ & $5$ & $\Pr \left\{ Y=y\right\} $ \\ -->
<!-- %$y$ &  &  &  &  &  &  &  &  \\ \hline\hline -->
<!-- %$0$ &  & $0$ & $0.01$ & $0.03$ & $0.05$ & $0.07$ & $0.09$ & $0.25$ \\ \hline -->
<!-- %$1$ &  & $0.01$ & $0.02$ & $0.04$ & $0.05$ & $0.06$ & $0.08$ & $0.26$ \\ -->
<!-- %\hline -->
<!-- %$2$ &  & $0.01$ & $0.03$ & $0.05$ & $0.05$ & $0.05$ & $0.06$ & $0.25$ \\ -->
<!-- %\hline -->
<!-- %$3$ &  & $0.01$ & $0.02$ & $0.04$ & $0.06$ & $0.06$ & $0.05$ & $0.24$ \\ -->
<!-- %\hline\hline -->
<!-- %$\Pr \left\{ X=x\right\} $ &  & $0.03$ & $0.08$ & $0.16$ & $0.21$ & $0.24$ & -->
<!-- %$0.28$ & $1$ \\ \hline -->
<!-- %\end{tabular} -->
<!-- %``` -->
<!-- %% -->
<div id="joint-probability-functions" class="section level2" number="7.1">
<h2>
<span class="header-section-number">7.1</span> Joint Probability Functions<a class="anchor" aria-label="anchor" href="#joint-probability-functions"><i class="fas fa-link"></i></a>
</h2>
<p>The joint PMF has two essential properties:</p>
<ol style="list-style-type: decimal">
<li><p>The value of the Joint PMF is always non-negative
<span class="math display">\[p_{X,Y}\left( x,y\right) \geq 0  \text{ for all possible pairs }\left(x,y\right)\]</span></p></li>
<li><p>The sum over all combinations of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> values is equal to one
<span class="math display">\[\sum_{x}\sum_{y}\Pr ( \left\{ X=x\cap Y=y\right\}) =1\]</span></p></li>
</ol>
<p>Similarly, the probability (mass) function of the discrete
random variable <span class="math inline">\(Y\)</span> is called its marginal probability (mass) function. It is obtained by summing the joint probabilities relating to pairs <span class="math inline">\((X,Y)\)</span> over all possible values of <span class="math inline">\(X\)</span>:
<span class="math display">\[\begin{equation*}
p_{Y}(y)=\sum_{x}p_{X,Y}(x,y).
\end{equation*}\]</span></p>
</div>
<div id="conditional-probability-1" class="section level2" number="7.2">
<h2>
<span class="header-section-number">7.2</span> Conditional Probability<a class="anchor" aria-label="anchor" href="#conditional-probability-1"><i class="fas fa-link"></i></a>
</h2>
<p>Recall that the <em>conditional</em> probability mass function of the discrete<br>
random variable <span class="math inline">\(Y\)</span>, <strong>given</strong> that the random variable <span class="math inline">\(X\)</span> takes the
value <span class="math inline">\(x\)</span>, is given by:
<span class="math display">\[\begin{equation*}
p_{Y|X}\left( y|x\right) =\frac{\Pr \left\{ X=x\cap Y=y\right\} }{%
P_{X}\left( X=x\right) }
\end{equation*}\]</span></p>
<p>Note this is a probability mass function for <span class="math inline">\(y,\)</span> with <span class="math inline">\(x\)</span> viewed as
fixed. Similarly:</p>
<p>Note this is a probability mass function for <span class="math inline">\(x,\)</span> with <span class="math inline">\(y\)</span> viewed as
fixed.</p>
<div id="independence-1" class="section level3" number="7.2.1">
<h3>
<span class="header-section-number">7.2.1</span> Independence<a class="anchor" aria-label="anchor" href="#independence-1"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li><p>Two discrete random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are <strong>independent</strong> if
<span class="math display">\[\begin{eqnarray*}
p_{X,Y}(x,y) &amp;=&amp;p_{X}(x)p_{Y}(y)\qquad \qquad \text{(discrete)} \\
%f_{X,Y}(x,y) &amp;=&amp;f_{X}(x)f_{Y}(y)\qquad \qquad \text{(continuous)}
\end{eqnarray*}\]</span>
for  values of <span class="math inline">\(x\)</span> and <span class="math inline">\(y.\)</span></p></li>
<li><p>Note that independence also implies that
<span class="math display">\[\begin{eqnarray*}
p_{X|Y}(x|y) &amp;=&amp;p_{X}(x)\text{ and }p_{Y|X}(y|x)=p_{Y}(y)\qquad \text{
(discrete)} \\
%f_{X|Y}(x|y) &amp;=&amp;f_{X}(x)\text{ and }f_{Y|X}(y|x)=f_{Y}(y)\qquad \text{
%(continuous)}
\end{eqnarray*}\]</span>
for  values of <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>.</p></li>
</ul>
<div class="inline-figure"><img src="img/07_bivariate_discrete_rv/ex_audrins.png" width="80%" style="display: block; margin: auto;"></div>
<div class="inline-figure"><img src="img/07_bivariate_discrete_rv/ex_audrins_2.png" width="80%" style="display: block; margin: auto;"></div>
</div>
</div>
<div id="expectations" class="section level2" number="7.3">
<h2>
<span class="header-section-number">7.3</span> Expectations<a class="anchor" aria-label="anchor" href="#expectations"><i class="fas fa-link"></i></a>
</h2>
<div class="inline-figure"><img src="img/07_bivariate_discrete_rv/ex_tot.png" width="80%" style="display: block; margin: auto;"></div>
<p>Equivalently, the **conditional expectation }of <span class="math inline">\(h\left( X,Y\right)\)</span>
 <span class="math inline">\(X=x\)</span> is defined as:
<span class="math display">\[\begin{equation*}
E\left[ h\left( X,Y\right) |x\right] =\sum_{y}h\left( x,y\right)
p_{Y|X}\left( y|x\right).
\end{equation*}\]</span></p>
<div class="inline-figure"><img src="img/07_bivariate_discrete_rv/ex_cond_audrins.png" width="80%" style="display: block; margin: auto;"></div>
<div id="iterated-expectations" class="section level3" number="7.3.1">
<h3>
<span class="header-section-number">7.3.1</span> Iterated Expectations<a class="anchor" aria-label="anchor" href="#iterated-expectations"><i class="fas fa-link"></i></a>
</h3>
<p>This notation emphasises that whenever we write down <span class="math inline">\(E[\cdot]\)</span> for an expectation we are taking that expectation with respect to the distribution implicit in the formulation of the argument.</p>
<p>The above formula is perhaps more easily understood using the more explicit notation:
<span class="math display">\[\begin{align*}
E_{(X,Y)}[h(X,Y)]&amp;=E_{(Y)}[E_{(X|Y)}[h(X,Y)]]\\
&amp;=E_{(X)}[E_{(Y|X)}[h(X,Y)]]
\end{align*}\]</span></p>
<p>This notation makes it clear what distribution is being used to evaluate the
expectation, the joint, the marginal or the conditional.</p>
</div>
</div>
<div id="covariance-and-correlation" class="section level2" number="7.4">
<h2>
<span class="header-section-number">7.4</span> Covariance and Correlation<a class="anchor" aria-label="anchor" href="#covariance-and-correlation"><i class="fas fa-link"></i></a>
</h2>
<p>Alternative formula<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;To get it, expand
&lt;span class="math display"&gt;\[\left(X-E\left[ X\right] \right) \left( Y-E\left[ Y\right] \right)=XY-E\left[ X\right]Y -XE\left[ Y\right] +E\left[ X\right]E\left[ Y\right]\]&lt;/span&gt; and make use of the properties of expectation.&lt;/p&gt;'><sup>1</sup></a> for <span class="math inline">\(Cov(X,Y)\)</span> is
<span class="math display">\[\begin{equation}
\boxed{Cov\left( X,Y\right) =E\left[ XY\right] -E\left[ X\right] E\left[ Y\right]\ .} \label{Cov}
\end{equation}\]</span></p>
<p>So, to compute the covariance from a table describing the joint behaviour of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, you have to:</p>
<ul>
<li>compute the joint expectation <span class="math inline">\(E[XY]\)</span>—you get it making use of the joint probability; </li>
<li>compute <span class="math inline">\(E[X]\)</span> and <span class="math inline">\(E[Y]\)</span>—you get using the marginal probability for <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>; </li>
<li>combine these expected values as in formula ().</li>
</ul>
<p>See example on page 13 for an illustrative computation.</p>
<div id="some-properties-of-covariances" class="section level3" number="7.4.1">
<h3>
<span class="header-section-number">7.4.1</span> Some Properties of Covariances<a class="anchor" aria-label="anchor" href="#some-properties-of-covariances"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li><p>The Cauchy-Schwartz Inequality states
<span class="math display">\[(E\left[ XY\right])^2\leq E\left[ X^2\right]E\left[ Y^2\right],\]</span>
with equality if, and only if, <span class="math inline">\(\Pr(Y=cX)=1\)</span> for some constant <span class="math inline">\(c\)</span>.</p></li>
<li><p>Let <span class="math inline">\(h(a)=E[(Y-aX)^2]\)</span> where <span class="math inline">\(a\)</span> is any number. Then <span class="math display">\[0\leq h(a)=E[(Y-aX)^2]=E[X^2]a^2-2E[XY]a+E[Y^2]\,.\]</span></p></li>
</ul>
<p>This is a quadratic in <span class="math inline">\(a\)</span>, and</p>
<ul>
<li>if <span class="math inline">\(h(a)&gt;0\)</span> the roots are real and <span class="math inline">\(4(E[XY])^2-4E[X^2]E[Y^2]&lt;0\)</span>,</li>
<li>if <span class="math inline">\(h(a)=0\)</span> for some <span class="math inline">\(a=c\)</span> then <span class="math inline">\(E[(Y-cX)^2]=0\)</span>, which implies that <span class="math inline">\(\Pr(Y-cX=0)=1\)</span>.</li>
</ul>
<p>Building on this remark, we have <span class="math inline">\(Cov(X,Y)&gt;0\)</span> if</p>
<ul>
<li><p>large values of <span class="math inline">\(X\)</span> tend to be associated with large
values of <span class="math inline">\(Y\)</span></p></li>
<li><p>small values of <span class="math inline">\(X\)</span> tend to be associated with small
values of <span class="math inline">\(Y\)</span></p></li>
<li><p><span class="math inline">\(Cov(X,Y)&lt;0\)</span> if</p></li>
<li><p>large values of <span class="math inline">\(X\)</span> tend to be  associated with  values of <span class="math inline">\(Y\)</span></p></li>
<li><p>small values of <span class="math inline">\(X\)</span> tend to be  associated with  values of <span class="math inline">\(Y\)</span></p></li>
<li><p>When <span class="math inline">\(Cov(X,Y)=0\)</span>, <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are said to be uncorrelated.</p></li>
<li><p>If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are two random variables (either discrete or continuous) with <span class="math inline">\(Cov(X,Y) \neq 0\)</span>, then:
<span class="math display">\[\begin{equation}
Var(X + Y) =  Var(X) + Var(Y) + 2 Cov(X,Y) \label{FullVar}
\end{equation}\]</span></p></li>
</ul>
<p>, where we read that in the case of independent random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>
we have
<span class="math display">\[Var(X + Y) =  Var(X) + Var(Y),\]</span>
which trivially follows from ()—indeed, for independent random variables, <span class="math inline">\(Cov(X,Y)\equiv 0\)</span>.</p>
<ul>
<li>The covariance depends upon the unit of measurement.</li>
</ul>
</div>
<div id="a-remark" class="section level3" number="7.4.2">
<h3>
<span class="header-section-number">7.4.2</span> A remark<a class="anchor" aria-label="anchor" href="#a-remark"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>If we scale <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, the covariance changes: For <span class="math inline">\(a,b&gt;0\)</span>%
<span class="math display">\[\begin{equation*}
Cov\left( aX,bY\right) =abCov\left( X,Y\right)
\end{equation*}\]</span>
</li>
</ul>
<p>Thus, we introduce the <strong>correlation</strong> between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is
<span class="math display">\[\begin{equation*}
corr\left( X,Y\right) =\frac{Cov\left( X,Y\right) }{\sqrt{Var\left( X\right)
Var\left( Y\right) }}
\end{equation*}\]</span></p>
<p>which depend upon the unit of measurement.</p>
<!-- % -->
<!-- % -->
<!-- %- Proof: For $a,b>0$% -->
<!-- %\begin{eqnarray*} -->
<!-- %corr\left( aX,bY\right)  &=&% -->
<!-- %%TCIMACRO{\TeXButton{Pause}{\pause}}% -->
<!-- % -->
<!-- %\pause% -->
<!-- %\frac{Cov\left( aX,bY\right) }{\sqrt{Var\left( aX\right) Var\left( bY\right) -->
<!-- %}}\medskip -->
<!-- %%TCIMACRO{\TeXButton{Pause}{\pause} }% -->
<!-- % -->
<!-- %\pause -->
<!-- %\\ -->
<!-- %&=&\frac{abCov\left( X,Y\right) }{\sqrt{a^{2}Var\left( X\right) -->
<!-- %b^{2}Var\left( Y\right) }}\medskip -->
<!-- %%TCIMACRO{\TeXButton{Pause}{\pause} }% -->
<!-- % -->
<!-- %\pause -->
<!-- %\\ -->
<!-- %&=&\frac{abCov\left( X,Y\right) }{ab\sqrt{Var\left( X\right) Var\left( -->
<!-- %Y\right) }}\medskip -->
<!-- %%TCIMACRO{\TeXButton{Pause}{\pause} }% -->
<!-- % -->
<!-- %\pause -->
<!-- %\\ -->
<!-- %&=&Corr\left( X,Y\right) \medskip -->
<!-- %%TCIMACRO{\TeXButton{Pause}{\pause}}% -->
<!-- % -->
<!-- %\pause% -->
<!-- %\end{eqnarray*} -->
<!-- % -->
</div>
<div id="an-important-property-of-correlation" class="section level3" number="7.4.3">
<h3>
<span class="header-section-number">7.4.3</span> An important property of correlation<a class="anchor" aria-label="anchor" href="#an-important-property-of-correlation"><i class="fas fa-link"></i></a>
</h3>
<p>The correlation is typically denoted by the Greek letter <span class="math inline">\(\rho\)</span>, so we have
<span class="math display">\[\rho(X,Y)= corr\left( X,Y\right).\]</span></p>

</div>
</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="limittheorems.html"><span class="header-section-number">6</span> 📝 Limit Theorems</a></div>
<div class="next"><a href="numericalmethods.html"><span class="header-section-number">8</span> 📝 Numerical Methods</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#bivariatediscreterv"><span class="header-section-number">7</span> 📝 Bivariate Discrete Random Variables</a></li>
<li><a class="nav-link" href="#joint-probability-functions"><span class="header-section-number">7.1</span> Joint Probability Functions</a></li>
<li>
<a class="nav-link" href="#conditional-probability-1"><span class="header-section-number">7.2</span> Conditional Probability</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#independence-1"><span class="header-section-number">7.2.1</span> Independence</a></li></ul>
</li>
<li>
<a class="nav-link" href="#expectations"><span class="header-section-number">7.3</span> Expectations</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#iterated-expectations"><span class="header-section-number">7.3.1</span> Iterated Expectations</a></li></ul>
</li>
<li>
<a class="nav-link" href="#covariance-and-correlation"><span class="header-section-number">7.4</span> Covariance and Correlation</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#some-properties-of-covariances"><span class="header-section-number">7.4.1</span> Some Properties of Covariances</a></li>
<li><a class="nav-link" href="#a-remark"><span class="header-section-number">7.4.2</span> A remark</a></li>
<li><a class="nav-link" href="#an-important-property-of-correlation"><span class="header-section-number">7.4.3</span> An important property of correlation</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>🃏 Probability I</strong>: Course Notes" was written by Dr. Daniel Flores Agreda (based on the Lecture by Prof. Davide La Vecchia). </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
