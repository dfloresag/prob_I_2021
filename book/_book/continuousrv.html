<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Continuous Random Variable | üÉè Probability I</title>
  <meta name="description" content="Course Materials" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Continuous Random Variable | üÉè Probability I" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course Materials" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Continuous Random Variable | üÉè Probability I" />
  
  <meta name="twitter:description" content="Course Materials" />
  

<meta name="author" content="Dr.¬†Daniel Flores Agreda (based on the Lecture by Prof.¬†Davide La Vecchia)" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="discreterv.html"/>
<link rel="next" href="limittheorems.html"/>
<script src="libs/header-attrs-2.6/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://www.unige.ch/gsem/fr/"><img src="img/gsem_en.png" alt="UNIGE Logo" width="200" class ="center"></a></li>
<li><a href="https://moodle.unige.ch/course/view.php?id=7133"><strong>Probability I (Spring 2021)</strong></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>About this lecture</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#the-contents-in-a-nutshell"><i class="fa fa-check"></i>The contents in a nutshell</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#practical-information"><i class="fa fa-check"></i>Practical information</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#who-we-are"><i class="fa fa-check"></i>Who we are</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#lectures"><i class="fa fa-check"></i>Lectures</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#exercises"><i class="fa fa-check"></i>Exercises</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#tools"><i class="fa fa-check"></i>Tools</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#a-world-of-data"><i class="fa fa-check"></i><b>1.1</b> A World of Data</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#what-to-expect-from-this-lecture"><i class="fa fa-check"></i><b>1.2</b> What to expect from this Lecture?</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="introduction.html"><a href="introduction.html#one-intuitive-illustration"><i class="fa fa-check"></i><b>1.2.1</b> One intuitive illustration</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#a-quick-reminder-of-mathematics"><i class="fa fa-check"></i><b>1.3</b> A quick reminder of Mathematics</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="introduction.html"><a href="introduction.html#powers-and-logarithms"><i class="fa fa-check"></i><b>1.3.1</b> Powers and Logarithms</a></li>
<li class="chapter" data-level="1.3.2" data-path="introduction.html"><a href="introduction.html#differentiation"><i class="fa fa-check"></i><b>1.3.2</b> Differentiation</a></li>
<li class="chapter" data-level="1.3.3" data-path="introduction.html"><a href="introduction.html#integration"><i class="fa fa-check"></i><b>1.3.3</b> Integration</a></li>
<li class="chapter" data-level="1.3.4" data-path="introduction.html"><a href="introduction.html#sums"><i class="fa fa-check"></i><b>1.3.4</b> Sums</a></li>
<li class="chapter" data-level="1.3.5" data-path="introduction.html"><a href="introduction.html#combinatorics"><i class="fa fa-check"></i><b>1.3.5</b> Combinatorics</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="settheory.html"><a href="settheory.html"><i class="fa fa-check"></i><b>2</b> Elements of Set Theory for Probability</a>
<ul>
<li class="chapter" data-level="2.1" data-path="settheory.html"><a href="settheory.html#definitions"><i class="fa fa-check"></i><b>2.1</b> Definitions</a></li>
<li class="chapter" data-level="2.2" data-path="settheory.html"><a href="settheory.html#some-definitions-from-set-theory"><i class="fa fa-check"></i><b>2.2</b> Some definitions from set theory</a></li>
<li class="chapter" data-level="2.3" data-path="settheory.html"><a href="settheory.html#the-venn-diagram"><i class="fa fa-check"></i><b>2.3</b> The Venn diagram</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="settheory.html"><a href="settheory.html#sample-space-and-events"><i class="fa fa-check"></i><b>2.3.1</b> Sample Space and Events</a></li>
<li class="chapter" data-level="2.3.2" data-path="settheory.html"><a href="settheory.html#exclusive-and-non-exclusive-events"><i class="fa fa-check"></i><b>2.3.2</b> Exclusive and Non-Exclusive Events</a></li>
<li class="chapter" data-level="2.3.3" data-path="settheory.html"><a href="settheory.html#union-and-intersection-of-events"><i class="fa fa-check"></i><b>2.3.3</b> Union and Intersection of Events</a></li>
<li class="chapter" data-level="2.3.4" data-path="settheory.html"><a href="settheory.html#complement"><i class="fa fa-check"></i><b>2.3.4</b> Complement</a></li>
<li class="chapter" data-level="2.3.5" data-path="settheory.html"><a href="settheory.html#some-properties-of-union-and-intersection"><i class="fa fa-check"></i><b>2.3.5</b> Some Properties of union and intersection</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="settheory.html"><a href="settheory.html#countable-and-uncountable-sets"><i class="fa fa-check"></i><b>2.4</b> Countable and Uncountable sets</a></li>
<li class="chapter" data-level="2.5" data-path="settheory.html"><a href="settheory.html#de-morgans-laws"><i class="fa fa-check"></i><b>2.5</b> De Morgan‚Äôs Laws:</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="settheory.html"><a href="settheory.html#first-law"><i class="fa fa-check"></i><b>2.5.1</b> First Law</a></li>
<li class="chapter" data-level="2.5.2" data-path="settheory.html"><a href="settheory.html#second-law"><i class="fa fa-check"></i><b>2.5.2</b> Second Law</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="settheory.html"><a href="settheory.html#de-morgans-theorem"><i class="fa fa-check"></i><b>2.6</b> De Morgan‚Äôs Theorem</a></li>
<li class="chapter" data-level="2.7" data-path="settheory.html"><a href="settheory.html#back-to-the-events"><i class="fa fa-check"></i><b>2.7</b> Back to the events</a></li>
<li class="chapter" data-level="2.8" data-path="settheory.html"><a href="settheory.html#some-references"><i class="fa fa-check"></i><b>2.8</b> Some references</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="axioms.html"><a href="axioms.html"><i class="fa fa-check"></i><b>3</b> Probability Axioms</a>
<ul>
<li class="chapter" data-level="3.1" data-path="axioms.html"><a href="axioms.html#an-axiomatic-definition-of-probability"><i class="fa fa-check"></i><b>3.1</b> An Axiomatic Definition of Probability</a></li>
<li class="chapter" data-level="3.2" data-path="axioms.html"><a href="axioms.html#properties-of-pcdot"><i class="fa fa-check"></i><b>3.2</b> Properties of <span class="math inline">\(P(\cdot)\)</span></a></li>
<li class="chapter" data-level="3.3" data-path="axioms.html"><a href="axioms.html#illustrations-of-use"><i class="fa fa-check"></i><b>3.3</b> Illustrations of use</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="axioms.html"><a href="axioms.html#flipping-coins"><i class="fa fa-check"></i><b>3.3.1</b> Flipping coins</a></li>
<li class="chapter" data-level="3.3.2" data-path="axioms.html"><a href="axioms.html#detecting-shoppers"><i class="fa fa-check"></i><b>3.3.2</b> Detecting shoppers</a></li>
<li class="chapter" data-level="3.3.3" data-path="axioms.html"><a href="axioms.html#de-morgans-law"><i class="fa fa-check"></i><b>3.3.3</b> De Morgan‚Äôs Law</a></li>
<li class="chapter" data-level="3.3.4" data-path="axioms.html"><a href="axioms.html#probability-union-and-complement"><i class="fa fa-check"></i><b>3.3.4</b> Probability, union, and complement</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="axioms.html"><a href="axioms.html#conditional-probability"><i class="fa fa-check"></i><b>3.4</b> Conditional probability</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="axioms.html"><a href="axioms.html#a-check"><i class="fa fa-check"></i><b>3.4.1</b> A check</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="axioms.html"><a href="axioms.html#independence"><i class="fa fa-check"></i><b>3.5</b> Independence</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="axioms.html"><a href="axioms.html#independence-another-characterization"><i class="fa fa-check"></i><b>3.5.1</b> Independence ‚Äì another characterization</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="axioms.html"><a href="axioms.html#theorem-i"><i class="fa fa-check"></i><b>3.6</b> Theorem I</a></li>
<li class="chapter" data-level="3.7" data-path="axioms.html"><a href="axioms.html#theorem-ii"><i class="fa fa-check"></i><b>3.7</b> Theorem II</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="axioms.html"><a href="axioms.html#guessing-in-a-multiple-choice-exam"><i class="fa fa-check"></i><b>3.7.1</b> Guessing in a multiple choice exam</a></li>
<li class="chapter" data-level="3.7.2" data-path="axioms.html"><a href="axioms.html#rent-car-maintenance"><i class="fa fa-check"></i><b>3.7.2</b> Rent car maintenance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="discreterv.html"><a href="discreterv.html"><i class="fa fa-check"></i><b>4</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="4.1" data-path="discreterv.html"><a href="discreterv.html#random-variables---what-are-they"><i class="fa fa-check"></i><b>4.1</b> Random variables - what are they?</a></li>
<li class="chapter" data-level="4.2" data-path="discreterv.html"><a href="discreterv.html#formal-definition-of-a-random-variable-i"><i class="fa fa-check"></i><b>4.2</b> Formal definition of a random variable (I)</a></li>
<li class="chapter" data-level="4.3" data-path="discreterv.html"><a href="discreterv.html#example-from-s-to-d-via-xcdot"><i class="fa fa-check"></i><b>4.3</b> Example: from <span class="math inline">\(S\)</span> to <span class="math inline">\(D\)</span>, via <span class="math inline">\(X(\cdot)\)</span></a></li>
<li class="chapter" data-level="4.4" data-path="discreterv.html"><a href="discreterv.html#formal-definition-of-a-random-variable-ii"><i class="fa fa-check"></i><b>4.4</b> Formal definition of a random variable (II)</a></li>
<li class="chapter" data-level="4.5" data-path="discreterv.html"><a href="discreterv.html#an-example-from-gambling"><i class="fa fa-check"></i><b>4.5</b> An Example from gambling</a></li>
<li class="chapter" data-level="4.6" data-path="discreterv.html"><a href="discreterv.html#discrete-random-variables"><i class="fa fa-check"></i><b>4.6</b> Discrete random variables</a></li>
<li class="chapter" data-level="4.7" data-path="discreterv.html"><a href="discreterv.html#cumulative-distribution-function-i"><i class="fa fa-check"></i><b>4.7</b> Cumulative Distribution Function (I)}</a></li>
<li class="chapter" data-level="4.8" data-path="discreterv.html"><a href="discreterv.html#distributional-summaries-for-discrete-random-variables"><i class="fa fa-check"></i><b>4.8</b> Distributional summaries for discrete random variables</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="discreterv.html"><a href="discreterv.html#some-illustrations-of-binomial"><i class="fa fa-check"></i><b>4.8.1</b> Some illustrations of Binomial</a></li>
<li class="chapter" data-level="4.8.2" data-path="discreterv.html"><a href="discreterv.html#binomial-distribution"><i class="fa fa-check"></i><b>4.8.2</b> Binomial Distribution</a></li>
<li class="chapter" data-level="4.8.3" data-path="discreterv.html"><a href="discreterv.html#binomial-distribution-1"><i class="fa fa-check"></i><b>4.8.3</b> Binomial Distribution</a></li>
<li class="chapter" data-level="4.8.4" data-path="discreterv.html"><a href="discreterv.html#binomial-distribution-2"><i class="fa fa-check"></i><b>4.8.4</b> Binomial Distribution</a></li>
<li class="chapter" data-level="4.8.5" data-path="discreterv.html"><a href="discreterv.html#poisson-distribution"><i class="fa fa-check"></i><b>4.8.5</b> Poisson Distribution</a></li>
<li class="chapter" data-level="4.8.6" data-path="discreterv.html"><a href="discreterv.html#poisson-distribution-1"><i class="fa fa-check"></i><b>4.8.6</b> Poisson Distribution</a></li>
<li class="chapter" data-level="4.8.7" data-path="discreterv.html"><a href="discreterv.html#some-illustrations-of-poisson"><i class="fa fa-check"></i><b>4.8.7</b> Some illustrations of Poisson</a></li>
<li class="chapter" data-level="4.8.8" data-path="discreterv.html"><a href="discreterv.html#poisson-distribution-2"><i class="fa fa-check"></i><b>4.8.8</b> Poisson Distribution</a></li>
<li class="chapter" data-level="4.8.9" data-path="discreterv.html"><a href="discreterv.html#poisson-distribution-3"><i class="fa fa-check"></i><b>4.8.9</b> Poisson Distribution</a></li>
<li class="chapter" data-level="4.8.10" data-path="discreterv.html"><a href="discreterv.html#poisson-distribution-link-to-binomial"><i class="fa fa-check"></i><b>4.8.10</b> Poisson Distribution (link to Binomial)</a></li>
<li class="chapter" data-level="4.8.11" data-path="discreterv.html"><a href="discreterv.html#poisson-distribution-link-to-binomial-1"><i class="fa fa-check"></i><b>4.8.11</b> Poisson Distribution (link to Binomial)</a></li>
<li class="chapter" data-level="4.8.12" data-path="discreterv.html"><a href="discreterv.html#poisson-distribution-example"><i class="fa fa-check"></i><b>4.8.12</b> Poisson Distribution: example</a></li>
<li class="chapter" data-level="4.8.13" data-path="discreterv.html"><a href="discreterv.html#the-hypergeometric-distribution"><i class="fa fa-check"></i><b>4.8.13</b> The Hypergeometric Distribution</a></li>
<li class="chapter" data-level="4.8.14" data-path="discreterv.html"><a href="discreterv.html#hypergeometric-distribution-example"><i class="fa fa-check"></i><b>4.8.14</b> Hypergeometric Distribution Example</a></li>
<li class="chapter" data-level="4.8.15" data-path="discreterv.html"><a href="discreterv.html#the-negative-binomial-distribution"><i class="fa fa-check"></i><b>4.8.15</b> The Negative Binomial Distribution</a></li>
<li class="chapter" data-level="4.8.16" data-path="discreterv.html"><a href="discreterv.html#the-negative-binomial-distribution-1"><i class="fa fa-check"></i><b>4.8.16</b> The Negative Binomial Distribution</a></li>
<li class="chapter" data-level="4.8.17" data-path="discreterv.html"><a href="discreterv.html#negative-binomial-distribution-example"><i class="fa fa-check"></i><b>4.8.17</b> Negative Binomial Distribution Example</a></li>
<li class="chapter" data-level="4.8.18" data-path="discreterv.html"><a href="discreterv.html#the-geometric-distribution"><i class="fa fa-check"></i><b>4.8.18</b> The Geometric Distribution</a></li>
<li class="chapter" data-level="4.8.19" data-path="discreterv.html"><a href="discreterv.html#the-geometric-distribution-1"><i class="fa fa-check"></i><b>4.8.19</b> The Geometric Distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="continuousrv.html"><a href="continuousrv.html"><i class="fa fa-check"></i><b>5</b> Continuous Random Variable</a>
<ul>
<li class="chapter" data-level="5.1" data-path="continuousrv.html"><a href="continuousrv.html#continuous-distributions"><i class="fa fa-check"></i><b>5.1</b> Continuous Distributions</a></li>
<li class="chapter" data-level="5.2" data-path="continuousrv.html"><a href="continuousrv.html#cumulative-distribution-function-cdf"><i class="fa fa-check"></i><b>5.2</b> Cumulative Distribution Function (CDF)</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="continuousrv.html"><a href="continuousrv.html#some-properties-of-the-normal-distribution"><i class="fa fa-check"></i><b>5.2.1</b> Some properties of the Normal distribution</a></li>
<li class="chapter" data-level="5.2.2" data-path="continuousrv.html"><a href="continuousrv.html#normal-an-example"><i class="fa fa-check"></i><b>5.2.2</b> Normal: an example</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="continuousrv.html"><a href="continuousrv.html#the-chi-squared-distribution"><i class="fa fa-check"></i><b>5.3</b> The Chi-squared distribution</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="continuousrv.html"><a href="continuousrv.html#some-plots-for-the-chi-squared"><i class="fa fa-check"></i><b>5.3.1</b> Some plots for the Chi-squared</a></li>
<li class="chapter" data-level="5.3.2" data-path="continuousrv.html"><a href="continuousrv.html#chi-squared-table"><i class="fa fa-check"></i><b>5.3.2</b> Chi-squared table</a></li>
<li class="chapter" data-level="5.3.3" data-path="continuousrv.html"><a href="continuousrv.html#chi-squared-table-illustration-of-its-use"><i class="fa fa-check"></i><b>5.3.3</b> Chi-squared table (illustration of its use)</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="continuousrv.html"><a href="continuousrv.html#the-student-t-distribution"><i class="fa fa-check"></i><b>5.4</b> The Student-t distribution</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="continuousrv.html"><a href="continuousrv.html#some-student-t-distributions"><i class="fa fa-check"></i><b>5.4.1</b> Some Student-t distributions</a></li>
<li class="chapter" data-level="5.4.2" data-path="continuousrv.html"><a href="continuousrv.html#student-t-table"><i class="fa fa-check"></i><b>5.4.2</b> Student-t table</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="continuousrv.html"><a href="continuousrv.html#some-f-distributions"><i class="fa fa-check"></i><b>5.5</b> Some F distributions</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="continuousrv.html"><a href="continuousrv.html#f-distribution-table-5-upper-tail"><i class="fa fa-check"></i><b>5.5.1</b> F distribution table (5% upper tail)</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="continuousrv.html"><a href="continuousrv.html#the-lognormal-distribution"><i class="fa fa-check"></i><b>5.6</b> The lognormal distribution</a></li>
<li class="chapter" data-level="5.7" data-path="continuousrv.html"><a href="continuousrv.html#exponential-distribution"><i class="fa fa-check"></i><b>5.7</b> Exponential distribution</a></li>
<li class="chapter" data-level="5.8" data-path="continuousrv.html"><a href="continuousrv.html#transformation-of-variables"><i class="fa fa-check"></i><b>5.8</b> Transformation of variables</a>
<ul>
<li class="chapter" data-level="5.8.1" data-path="continuousrv.html"><a href="continuousrv.html#transformation-of-discrete-random-variables"><i class="fa fa-check"></i><b>5.8.1</b> Transformation of discrete random variables</a></li>
<li class="chapter" data-level="5.8.2" data-path="continuousrv.html"><a href="continuousrv.html#transformation-of-variables-using-the-cdf"><i class="fa fa-check"></i><b>5.8.2</b> Transformation of variables using the CDF</a></li>
<li class="chapter" data-level="5.8.3" data-path="continuousrv.html"><a href="continuousrv.html#function-1-to-1-and-monotone-decreasing"><i class="fa fa-check"></i><b>5.8.3</b> Function 1-to-1 and monotone decreasing</a></li>
<li class="chapter" data-level="5.8.4" data-path="continuousrv.html"><a href="continuousrv.html#transformation-of-continuous-rv-through-pdf"><i class="fa fa-check"></i><b>5.8.4</b> Transformation of continuous RV through pdf</a></li>
<li class="chapter" data-level="5.8.5" data-path="continuousrv.html"><a href="continuousrv.html#example-of-transformation-using-pdf"><i class="fa fa-check"></i><b>5.8.5</b> Example of transformation using pdf</a></li>
<li class="chapter" data-level="5.8.6" data-path="continuousrv.html"><a href="continuousrv.html#a-caveat"><i class="fa fa-check"></i><b>5.8.6</b> A caveat</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="continuousrv.html"><a href="continuousrv.html#the-big-picture"><i class="fa fa-check"></i><b>5.9</b> The big picture</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="limittheorems.html"><a href="limittheorems.html"><i class="fa fa-check"></i><b>6</b> Limit Theorems</a>
<ul>
<li class="chapter" data-level="6.1" data-path="limittheorems.html"><a href="limittheorems.html#sequences-of-random-variables"><i class="fa fa-check"></i><b>6.1</b> Sequences of Random Variables</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="limittheorems.html"><a href="limittheorems.html#example-bernoulli-trials-and-their-sum"><i class="fa fa-check"></i><b>6.1.1</b> Example: Bernoulli Trials and their sum</a></li>
<li class="chapter" data-level="6.1.2" data-path="limittheorems.html"><a href="limittheorems.html#example-bernoulli-trials-and-limit-behaviour"><i class="fa fa-check"></i><b>6.1.2</b> Example: Bernoulli Trials and limit behaviour</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="limittheorems.html"><a href="limittheorems.html#convergence-in-probability-oversetprightarrow"><i class="fa fa-check"></i><b>6.2</b> Convergence in Probability (<span class="math inline">\(\overset{p}{\rightarrow }\)</span>)</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="limittheorems.html"><a href="limittheorems.html#operational-rules-for-oversetprightarrow"><i class="fa fa-check"></i><b>6.2.1</b> Operational Rules for <span class="math inline">\(\overset{p}{\rightarrow }\)</span></a></li>
<li class="chapter" data-level="6.2.2" data-path="limittheorems.html"><a href="limittheorems.html#convergence-of-sample-moments-as-a-motivation"><i class="fa fa-check"></i><b>6.2.2</b> Convergence of Sample Moments as a motivation‚Ä¶</a></li>
<li class="chapter" data-level="6.2.3" data-path="limittheorems.html"><a href="limittheorems.html#the-weak-law-of-large-numbers-wlln"><i class="fa fa-check"></i><b>6.2.3</b> The Weak Law of Large Numbers (WLLN)</a></li>
<li class="chapter" data-level="6.2.4" data-path="limittheorems.html"><a href="limittheorems.html#the-wlln-and-chebyshevs-inequality"><i class="fa fa-check"></i><b>6.2.4</b> The WLLN and Chebyshev‚Äôs Inequality</a></li>
<li class="chapter" data-level="6.2.5" data-path="limittheorems.html"><a href="limittheorems.html#chebyshevs-and-markovs-inequality"><i class="fa fa-check"></i><b>6.2.5</b> Chebyshev‚Äôs (and Markov‚Äôs) Inequality</a></li>
<li class="chapter" data-level="6.2.6" data-path="limittheorems.html"><a href="limittheorems.html#example-markovs-inequality"><i class="fa fa-check"></i><b>6.2.6</b> Example: Markov‚Äôs Inequality</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html"><i class="fa fa-check"></i><b>7</b> Bivariate Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="7.1" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#joint-probability-functions"><i class="fa fa-check"></i><b>7.1</b> Joint Probability Functions</a></li>
<li class="chapter" data-level="7.2" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#marginal-probability-mass-functions"><i class="fa fa-check"></i><b>7.2</b> Marginal probability (mass) functions</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#first-example"><i class="fa fa-check"></i><b>7.2.1</b> First Example</a></li>
<li class="chapter" data-level="7.2.2" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#empirical-example"><i class="fa fa-check"></i><b>7.2.2</b> Empirical Example</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#conditional-probability-mass-function"><i class="fa fa-check"></i><b>7.3</b> Conditional probability mass function</a></li>
<li class="chapter" data-level="7.4" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#independence-1"><i class="fa fa-check"></i><b>7.4</b> Independence</a></li>
<li class="chapter" data-level="7.5" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#expectations-for-jointly-distributed-discrete-rvs"><i class="fa fa-check"></i><b>7.5</b> Expectations for Jointly Distributed Discrete RVs</a></li>
<li class="chapter" data-level="7.6" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#iterated-expectations"><i class="fa fa-check"></i><b>7.6</b> Iterated Expectations</a></li>
<li class="chapter" data-level="7.7" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#expectations-for-jointly-distributed-discrete-rvs-1"><i class="fa fa-check"></i><b>7.7</b> Expectations for Jointly Distributed Discrete RVs</a></li>
<li class="chapter" data-level="7.8" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#some-properties-of-covariances"><i class="fa fa-check"></i><b>7.8</b> Some Properties of Covariances</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#a-remark"><i class="fa fa-check"></i><b>7.8.1</b> A remark</a></li>
<li class="chapter" data-level="7.8.2" data-path="bivariatediscreterv.html"><a href="bivariatediscreterv.html#an-important-property-of-correlation"><i class="fa fa-check"></i><b>7.8.2</b> An important property of correlation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="numericalmethods.html"><a href="numericalmethods.html"><i class="fa fa-check"></i><b>8</b> Numerical Methods</a>
<ul>
<li class="chapter" data-level="8.1" data-path="numericalmethods.html"><a href="numericalmethods.html#introduction-to-simulation"><i class="fa fa-check"></i><b>8.1</b> Introduction to simulation</a></li>
<li class="chapter" data-level="8.2" data-path="numericalmethods.html"><a href="numericalmethods.html#simulation-procedure"><i class="fa fa-check"></i><b>8.2</b> Simulation procedure</a></li>
<li class="chapter" data-level="8.3" data-path="numericalmethods.html"><a href="numericalmethods.html#simulation-in-r"><i class="fa fa-check"></i><b>8.3</b> Simulation in R</a></li>
<li class="chapter" data-level="8.4" data-path="numericalmethods.html"><a href="numericalmethods.html#coin-tossing"><i class="fa fa-check"></i><b>8.4</b> Coin tossing</a></li>
<li class="chapter" data-level="8.5" data-path="numericalmethods.html"><a href="numericalmethods.html#summarizing"><i class="fa fa-check"></i><b>8.5</b> Summarizing</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">üÉè Probability I</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="continuousrv" class="section level1" number="5">
<h1><span class="header-section-number">Chapter 5</span> Continuous Random Variable</h1>
<div id="continuous-distributions" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Continuous Distributions</h2>
<p>The mentioned random variables provide two examples of a class of random variables which are different from what we have seen so far.
Specifically, the examples emphasize that,
unlike discrete random variables, the considered variables are <strong>continuous random variables</strong>:
they can take any value in an interval.</p>
<p>This means we cannot simply <em>list</em> all possible values of the
random variable, because there are (infinitely many) an uncountable number of possible outcomes that might occur.</p>
<p>We construct a probability distribution by assigning a positive probability to each and every possible interval of values that can occur. This is done by defining what is called a .</p>
<p>So, graphically, we have</p>
</div>
<div id="cumulative-distribution-function-cdf" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> Cumulative Distribution Function (CDF)</h2>
<p>Let <span class="math inline">\(X\)</span> be a random variable taking values in the interval <span class="math inline">\((a,b]\)</span> since:</p>
<ul>
<li><span class="math inline">\(\color{red}{F_{X}\left( x\right)}\)</span> is zero for all <span class="math inline">\(x&lt;a\)</span></li>
<li><span class="math inline">\(0&lt;\color{red}{F_{X}\left( x\right)}&lt;1\)</span> for all <span class="math inline">\(x\)</span> in <span class="math inline">\((a,b)\)</span> and</li>
<li><span class="math inline">\(\color{red}{F_{X}\left( x\right)}=1\)</span> for all <span class="math inline">\(x\geq b\)</span>.</li>
</ul>
<p>Then, the Probability Density Function (pdf) of <span class="math inline">\(X\)</span> at the point <span class="math inline">\(x\)</span> is defined as</p>
<p><span class="math display">\[f_{X}\left( x\right) =\frac{d\color{red}{F_{X}(x)}}{dx}.\]</span></p>
<p>‚Ä¶ an illustration ‚Ä¶</p>
<!-- % -->
<!-- %-  Let $X$ be a continuous random variable with continuous CDF $F_{X}\left( x\right)$. -->
<!-- % -->
<!-- %-  Then the Probability Density Function (% -->
<!-- %%TCIMACRO{\TeXButton{blue}{\color{blue}}}% -->
<!-- % -->
<!-- %\color{blue}% -->
<!-- % -->
<!-- %PDF% -->
<!-- %%TCIMACRO{\TeXButton{black}{}}% -->
<!-- % -->
<!-- %% -->
<!-- % -->
<!-- %) of $X$ at the point $x$ is defined as -->
<!-- %\begin{equation*} -->
<!-- %\color{blue}{f_{X}\left( x\right) =\frac{dF_{X}(x)}{dx}}\,. -->
<!-- %\end{equation*}% -->
<!-- %%for all $x\in \mathbb{R}$. -->
<!-- %-  For the illustrated CDF we have: -->
<!-- % -->
<!-- %%TCIMACRO{% -->
<!-- %%\FRAME{ftbpF}{4.67in}{2.5624in}{0pt}{}{}{generic_pdf.bmp}{% -->
<!-- %%\special{language "Scientific Word";type "GRAPHIC";maintain-aspect-ratio TRUE;display "USEDEF";valid_file "F";width 4.67in;height 2.5624in;depth 0pt;original-width 13.4859in;original-height 7.389in;cropleft "0";croptop "1";cropright "1";cropbottom "0";filename 'generic_pdf.bmp';file-properties "XNPEU";}}}% -->
<!-- % -->
<!-- %\begin{figure}[ptb]\centering -->
<!-- %\includegraphics[width=0.95\textwidth]{generic_pdf__1.pdf}% -->
<!-- %\end{figure}% -->
<p>‚Ä¶  ‚Ä¶</p>
<p>%</p>
<!-- %\frametitle{Probability Density Function (pdf)} -->
<!-- %  -->
<!-- % ... and a cartoon ... -->
<!-- %  -->
<!-- %\begin{figure}[ptb]\centering -->
<!-- %\includegraphics[natheight=7.6in, natwidth=13.4859in, height=2.4in, width=4.67in]{aaa.pdf}% -->
<!-- %\end{figure}% -->
<!-- % -->
<!-- % -->
<p>In the illustration <span class="math inline">\(X\)</span> is a random variable taking values in the interval <span class="math inline">\((a,b]\)</span>, and the pdf $f_{X}( x) $ is non-zero only in <span class="math inline">\((a,b)\)</span>. More generally we have, for a variable taking values on the whole real line (<span class="math inline">\(\mathbb{R}\)</span>)</p>
<!-- %by the \textbf{\emph{fundamental theorem of integral calculus}}:% -->
<!-- %\begin{equation*} -->
<!-- %F_{X}(x)=\int_{-\infty}^{x}f_{X}\left( t\right) dt -->
<!-- %\end{equation*} -->
<!-- %for any value of $x\in \mathbb{R}$. Thus we  deduce that the PDF $f_{X}\left( x\right) $ is such that -->
<!-- % -->
<!-- %-  $f_{X}\left( x\right) \geq 0$ for all $x\in \mathbb{R}$ -->
<!-- %-  The total area under the curve $f_{X}\left( x\right) $ is 1, i.e. $ -->
<!-- %\int_{-\infty }^{\infty }f_{X}\left( x\right) dx=1.$ -->
<!-- %-  Note that for some intervals of the real line, we can have $f_{X}\left( x\right) =0$. -->
<!-- % -->
<!-- %Moreover (see the previous graphical illustration), recall that: -->
<ul>
<li>the  yields

<span class="math display">\[F_{X}\left( x\right) =\Pr \left( X\leq x\right) =\int_{-\infty}^{x}\color{blue}f_{X}\left(
t\right)\color{red} dt,\]</span>%</li>
</ul>
<p>the area under the CDF between <span class="math inline">\(-\infty\)</span> and <span class="math inline">\(x\)</span></p>
<ul>
<li>or in terms of derivative
<span class="math display">\[\color{blue}{f_{X}\left( x\right)} = \frac{d\color{red}{F_{X}(x)}}{dx}\]</span></li>
</ul>
<p>for all <span class="math inline">\(x\)</span>, the derivative of the CDF.</p>
<p>Most of the pdfs that we are going to consider are bell-shaped. So, typically, we will have</p>
<p>For <strong>discrete</strong> random variables, we use summation:</p>
<p><span class="math display">\[\begin{equation*}
E\left[ X\right] =\sum_{i}x_{i}p_{i}
\end{equation*}\]</span></p>
<ul>
<li>the mean (or expected) value of a discrete random variable <span class="math inline">\(X\)</span></li>
<li>is found by summing the product of <span class="math inline">\(x_{i}\)</span> and <span class="math inline">\(p_{i}=\Pr (X=x_{i})\)</span>,</li>
<li>for each possible value <span class="math inline">\(x_{i}\)</span></li>
</ul>
<p>For <strong>continuous</strong> random variables, we use itegration:</p>
<p><span class="math display">\[\begin{equation*}
E\left[ X\right] =\int_{a}^{b}x\,f_{X}\left( x\right) dx
\end{equation*}\]</span></p>
<ul>
<li>the mean (or expected) value of the continuous random variable <span class="math inline">\(X\)</span></li>
<li>is found by integrating the product of <span class="math inline">\(x\)</span> and its  $f_{X}( x) $</li>
<li>over the range of possible values of <span class="math inline">\(x\)</span></li>
</ul>
<p>Recall that, for  random variables, we defined the variance as:</p>
<p><span class="math display">\[\begin{equation*}
Var\left( X\right) =\sum_{i}\left( x_{i}-E\left[ X\right] \right) ^{2}\Pr
\left( X=x_{i}\right)
\end{equation*}\]</span></p>
<p>Similarly, for  random variables, we use integration:</p>
<p><span class="math display">\[\begin{equation*}
Var\left( X\right) =\int_{a}^{b}\left( x-E\left[ X\right] \right)^{2}\,f_{X}\left( x\right) dx
\end{equation*}\]</span></p>
<!-- %\frametitle{The expected value of a function of a random variable} -->
<!-- % -->
<!-- %Building on this intuition, we generalise to finding the expected value of $h(X)$.  -->
<!-- % -->
<!-- % -->
<!-- %For \textbf{discrete} random variables:% -->
<!-- %\begin{equation*} -->
<!-- %E\left[ h\left( X\right) \right] =\sum_{i}h\left( x_{i}\right) \Pr \left( -->
<!-- %X=x_{i}\right) -->
<!-- %\end{equation*} -->
<!-- % -->
<!-- %  -->
<!-- % -->
<!-- %For \textbf{continuous} random variables:% -->
<!-- %\begin{equation*} -->
<!-- %Var\left( X\right) =\int_{a}^{b}h\left( x\right) \,f_{X}\left( x\right) dx -->
<!-- %\end{equation*} -->
<p>As with discrete random variables, the following properties hold when <span class="math inline">\(X\)</span> is a continuous random variable and <span class="math inline">\(c\)</span> is any real number (namely, <span class="math inline">\(c \in \mathbb{R}\)</span>):</p>
<ul>
<li><span class="math inline">\(E\left[ cX\right] =cE\left[ X\right]\)</span></li>
<li><span class="math inline">\(E\left[ c+X\right] =c+E\left[ X\right]\)</span></li>
<li><span class="math inline">\(Var\left( cX\right) =c^{2}Var\left( X\right)\)</span></li>
<li><span class="math inline">\(Var\left( c+X\right) =Var\left( X\right)\)</span></li>
</ul>
<p>Let us consider, for instance, the following proofs for first two properties%</p>
<p><span class="math display">\[\begin{eqnarray*}
E\left[ cX\right] &amp;=&amp;\int \left( cx\right) f_{X}\left( x\right) dx \\
&amp;=&amp;c\int xf_{X}\left( x\right) dx \\
&amp;=&amp;cE\left[ X\right].
\end{eqnarray*}\]</span></p>
<p><span class="math display">\[\begin{eqnarray*}
E\left[ c+X\right] &amp;=&amp;\int \left( c+x\right) f_{X}\left( x\right) dx \\
&amp;=&amp;\int cf_{X}\left( x\right) dx+\int xf_{X}\left( x\right) dx \\
&amp;=&amp;c\times 1+E\left[ X\right] \\
&amp;=&amp;c+E\left[ X\right].
\end{eqnarray*}\]</span></p>
<ul>
<li>Continuous Uniform</li>
<li>Normal</li>
<li>Chi-squared</li>
<li>Student‚Äôs <span class="math inline">\(t\)</span></li>
<li><span class="math inline">\(F\)</span></li>
<li>Lognormal</li>
<li>Exponential</li>
<li>‚Ä¶and more</li>
</ul>
<!-- %-  The PDF is given by% -->
<!-- %\begin{equation*} -->
<!-- %f_{X}\left( x\right) =\left\{ -->
<!-- %\begin{array}{l} -->
<!-- %\frac{1}{b-a}\text{, for }a<x<b \\ -->
<!-- %0\text{, \quad otherwise}% -->
<!-- %\end{array}% -->
<!-- %\right. -->
<!-- %\end{equation*} -->
<!-- % -->
<!-- %% -->
<!-- % -->
<!-- % -->
<!-- %\frametitle{Continuous uniform distribution} -->
<!-- % -->
<!-- %```{definition} -->
<!-- %We say $X$ has a continuous **uniform} distribution over the -->
<!-- %interval $(a,b]$, denoted as $X\sim Unif(a,b)$, when the CDF and pdf are given by -->
<!-- %$$ -->
<!-- %\color{red}{F_X\left( x\right)}=\left\{ -->
<!-- %                           \begin{array}{ll} -->
<!-- %                             0, & \hbox{$x\leq a$;} \\ -->
<!-- %                             \frac{(x-a)}{(b-a)}, & \hbox{$a<x\leq b$;} \\ -->
<!-- %                             1, & \hbox{$x>b$.} -->
<!-- %                           \end{array} -->
<!-- %                         \right.\mbox{and}~\color{blue}{f_{X}\left( x\right)} =\left\{ -->
<!-- %\begin{array}{l} -->
<!-- %\frac{1}{b-a}\text{, for }a<x<b \\ -->
<!-- %0\text{, \quad otherwise}% -->
<!-- %\end{array}% -->
<!-- %\right. , -->
<!-- %$$ -->
<!-- %respectively. -->
<!-- %``` -->
<!-- %%-  The PDF is given by% -->
<!-- %%\begin{equation*} -->
<!-- %%f_{X}\left( x\right) =\left\{ -->
<!-- %%\begin{array}{l} -->
<!-- %%\frac{1}{b-a}\text{, for }a<x<b \\ -->
<!-- %%0\text{, \quad otherwise}% -->
<!-- %%\end{array}% -->
<!-- %%\right. -->
<!-- %%\end{equation*} -->
<!-- %% -->
<p>As a graphical illustration, let us consider the case when <span class="math inline">\(a=0\)</span> and <span class="math inline">\(b=1\)</span>. So, we have:</p>
<p>The expected value of <span class="math inline">\(X\)</span> is%
<span class="math display">\[\begin{eqnarray*}
E\left[ X\right] &amp;=&amp;\int_{a}^{b}\frac{x}{\left( b-a\right) }dx \\
&amp;=&amp;\left. \frac{x^{2}}{2\left( b-a\right) }\right\vert _{a}^{b} \\
&amp;=&amp;\frac{b^{2}}{2\left( b-a\right) }-\frac{a^{2}}{2\left( b-a\right) } \\
&amp;=&amp;\frac{a+b}{2}
\end{eqnarray*}\]</span></p>
<p>The variance of <span class="math inline">\(X\)</span> is%
<span class="math display">\[\begin{eqnarray*}
Var\left( X\right) &amp;=&amp;\int_{a}^{b}\left( x-\left( \frac{a+b}{2}\right)
\right) ^{2}\frac{1}{b-a}dx \\
&amp;=&amp;E\left[ X^{2}\right] -E\left[ X\right] ^{2}
\end{eqnarray*}\]</span></p>
<p>We know the second term
<span class="math display">\[\begin{equation*}
E\left[ X\right] ^{2}=\left( \frac{a+b}{2}\right) ^{2},
\end{equation*}\]</span></p>
<p>so we‚Äôve just to work out%
<span class="math display">\[\begin{eqnarray*}
E\left[ X^{2}\right] &amp;=&amp;\int_{a}^{b}\frac{x^{2}}{b-a}dx =\left. \frac{x^{3}}{3\left( b-a\right) }\right\vert _{a}^{b} \\
&amp;=&amp;\frac{b^{3}-a^{3}}{3\left( b-a\right) } = \frac{(b-a)\left( ab+a^{2}+b^{2}\right)}{3\left( b-a\right) } \\
&amp;=&amp;\frac{\left( ab+a^{2}+b^{2}\right) }{3}.
\end{eqnarray*}\]</span></p>
<p>Putting together, we get that the variance of <span class="math inline">\(X\)</span>:%
<span class="math display">\[\begin{eqnarray*}
Var\left( X\right) &amp;=&amp;\frac{\left( ab+a^{2}+b^{2}\right) }{3}-\left( \frac{%
a+b}{2}\right) ^{2} \\
&amp;=&amp;\frac{1}{12}\left( a-b\right) ^{2}
\end{eqnarray*}\]</span></p>
<p>The Normal distribution was ‚Äúdiscovered‚Äù in the eighteenth
century when scientists observed an astonishing degree of
regularity in the behavior of measurement errors. They found that
the patterns (distributions) that they observed, and which they
attributed to chance, could be closely approximated by continuous
curves which they christened the ``normal curve of errors".</p>
<p>The mathematical properties of these curves were first studied by</p>
<ul>
<li>Abraham de Moivre (1667-1745),</li>
<li>Pierre Laplace (1749-1827), and then</li>
<li>Karl Gauss (1777-1855), who also lent his name to the
distribution.</li>
</ul>
<p>The pdf of the normal distribution is</p>
<ul>
<li>`bell-shaped‚Äô</li>
<li>symmetric</li>
<li>unimodal</li>
<li>the mean, median and mode are all equal.</li>
</ul>
<p>%</p>
<p>%</p>
<p>%</p>
<p>First let us establish that <span class="math inline">\(\phi_{(\mu,\sigma)}(x)\)</span> can serve as a
genuine density function. Integrating with respect to <span class="math inline">\(x\)</span> using
 we obtain
<span class="math display">\[\begin{eqnarray*}
\int_{-\infty}^{\infty}\phi_{(\mu,\sigma)}(x)dx&amp;=&amp;
\int_{-\infty}^{\infty}\frac{1}{\sqrt{2\pi\sigma^2}}\exp^{\{-\frac{(x-\mu)^2}{2\sigma^2}\}}dx
\\
 &amp;=&amp;\int_{-\infty}^{\infty}\frac{1}{\sqrt{2\pi}}\exp^{\{-\frac{z^2}{2}\}}dz
\end{eqnarray*}\]</span>
where <span class="math inline">\(z=(x-\mu)/\sigma\)</span>. But the second integral on the right
hand side equals
<span class="math display">\[
\frac{2}{\sqrt{2\pi}}\underbrace{\int_0^{\infty}\exp^{\{-z^2/2\}}dz}_{={\sqrt{2\pi}} \big/ {2}}
\]</span>
which is <strong>a known standard integral</strong>.</p>
<p>Thus:</p>
<ul>
<li><p>The function <span class="math inline">\(\phi_{(\mu,\sigma)}(x)\)</span> does indeed define the pdf of a random variable with a mean of <span class="math inline">\(\mu\)</span> and a variance of <span class="math inline">\(\sigma^2\)</span>.</p></li>
<li><p>This was established by transforming from <span class="math inline">\(X\)</span> to <span class="math inline">\(Z\)</span> via the substitution <span class="math inline">\(Z=(X-\mu)/\sigma\)</span>. Such a variable
is said to be standardised. Note also that the resulting integrand
<span class="math display">\[
\frac{1}{\sqrt{2\pi}}\exp^{\{-\frac{z^2}{2}\}}=\phi_{(0,1)}(z)\,,
\]</span>
is the pdf of a random variable <span class="math inline">\(Z\sim \N(0,1)\)</span>.</p></li>
<li><p>If <span class="math inline">\(Z\sim \N(0,1)\)</span> then <span class="math inline">\(Z\)</span> is called a √ästandard normal random variate because
$
[Z]=0$ and <span class="math inline">\(\textsf{Var}(Z)=1\)</span></p></li>
<li><p>Because of the special role that the standard normal distribution has in
calculations involving the normal distribution its pdf is given the special notation
<span class="math display">\[\phi(z)=\phi_{(0,1)}(z).\]</span></p></li>
</ul>
<p>The basic feature that underlies calculations involving the Normal distribution:</p>
<ul>
<li><p><span class="math display">\[X\sim \N\left( \mu ,\sigma ^{2}\right)\Leftrightarrow Z=\frac{\left( X-\mu \right) }{\sigma }\sim \N\left( 0,1\right)\]</span></p></li>
<li><p>We can always transform from <span class="math inline">\(X\)</span> to <span class="math inline">\(Z\)</span> by <code>shifting' and</code>re-scaling‚Äô:%
<span class="math display">\[\begin{equation*}
Z=\frac{X-\mu }{\sigma } \ (\text{for the random variable}) \quad\mbox{and}\quad z=\frac{x-\mu }{\sigma }\,  \ (\text{for its values}) ,
\end{equation*}\]</span></p></li>
<li><p>and return back to <span class="math inline">\(X\)</span> by a <code>re-scaling' and</code>shifting‚Äô:%
<span class="math display">\[\begin{equation*}
X=\sigma Z+\mu  \ (\text{for the random variable}) \quad\mbox{and}\quad x=\sigma z+\mu\, \ (\text{for its values}) .
\end{equation*}\]</span></p></li>
<li><p>Thus statements about a Normal random variable can always be translated into equivalent statements about a standard Normal random variable, and vice versa.</p></li>
</ul>
<p>In pictures:
Start from <span class="math inline">\(X \sim \mathcal{N}(5,3)\)</span>; then define <span class="math inline">\(Y=X-5\)</span>, which is a recentered/shifted <span class="math inline">\(X\)</span> (it‚Äôs centered at 0 and has the same variance as <span class="math inline">\(X\)</span>); finally define <span class="math inline">\(Z\)</span>, which is a recentered/shifted and rescaled <span class="math inline">\(X\)</span> (it‚Äôs centered at 0 and has unit variance).</p>
<p>In formulae:</p>
<ul>
<li>For $X( ,^{2}) $, the CDF is given by%
<span class="math display">\[\Phi_{(\mu,\sigma)}\left( x\right) =\int_{-\infty }^{x}\frac{1}{\sqrt{2\pi \sigma ^{2}}}\exp^{ \left\{ -\frac{1}{2\sigma ^{2}}\left( t-\mu \right) ^{2}\right\}} dt\]</span></li>
<li>To calculate <span class="math inline">\(\Phi_{(\mu,\sigma)}\left( x\right)=\Pr(\{X\leq x\})\)</span> we use integration by substitution, once again, to give</li>
</ul>
<p><span class="math display">\[\begin{eqnarray*}
\Pr(\{ X\leq x\} )&amp;=&amp;\int_{-\infty}^x\frac{1}{\sqrt{2\pi\sigma^2}}\exp^{\left\{-\frac{(t-\mu)^2}{2\sigma^2}\right\}}dt\\
 &amp;=&amp;\int_{-\infty}^z\phi(s)ds\\
  &amp;=&amp;P(\{Z\leq z\})
\end{eqnarray*}\]</span></p>
<p>where <span class="math inline">\(z=(x-\mu)/\sigma\)</span>, <span class="math inline">\(s=(t-\mu)/\sigma\)</span> and <span class="math inline">\(ds=dt/\sigma\)</span>.
- The required probability has been mapped into a corresponding probability for a standard Normal random variable.</p>
<ul>
<li>We can evaluate the probabilities</li>
</ul>
<p><span class="math display">\[\Pr(\{Z\leq z\})=\Phi(z)=\int_{-\infty}^z\phi(s)ds\]</span></p>
<p>either directly using a computer or indirectly via Standard Normal
Tables.
- Standard Normal Tables give values of the integral <span class="math inline">\(\Phi(z)\)</span> for various values of <span class="math inline">\(z\geq 0\)</span>. (The tables are themselves
calculated using a computer, of course.)
- For negative values of <span class="math inline">\(z\)</span> the symmetry property of <span class="math inline">\(\phi(z)\)</span> ( <span class="math inline">\(\phi(z)=\phi(-z)\)</span>) tells us that
<span class="math display">\[\Phi(-z)=1-\Phi(z)\,\]</span>
- Similarly, if <span class="math inline">\(X\sim \N\left( \mu ,\sigma ^{2}\right)\)</span> then</p>
<p><span class="math display">\[\begin{eqnarray*}
\Pr(\{x_1&lt;X\leq x_2\})&amp;=&amp;\Pr(\{z_1&lt;Z\leq z_2\})\\
&amp;=&amp;\Phi(z_2)-\Phi(z_1)
\end{eqnarray*}\]</span>
where <span class="math inline">\(z_1=(x_1-\mu)/\sigma\)</span> and <span class="math inline">\(z_2=(x_2-\mu)/\sigma\)</span>.</p>
<ul>
<li>Standard Normal Tables give values of the standard normal integral <span class="math inline">\(\Phi(z)\)</span> for various values of <span class="math inline">\(z\geq 0\)</span>. Values for negative <span class="math inline">\(z\)</span> are obtained via symmetry.
<!-- %-  Other Normal tables give either $1-\Phi(z)$ (tail area) or $\Phi(z)-0.5$! --></li>
</ul>
‚Ä¶. and you can use these tables to compute integrals/probabilities of the type:
<div id="some-properties-of-the-normal-distribution" class="section level3" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Some properties of the Normal distribution</h3>
<p>%</p>
<p>The shaded areas under the pdfs are (approximately) equivalent to <span class="math inline">\(0.683\)</span>, <span class="math inline">\(0.954\)</span> and <span class="math inline">\(0.997\)</span>,
respectively. So we state the following ‚Ä¶.</p>
<p><strong>‚Ä¶ rule `68 ‚Äì 95 ‚Äì 99.7‚Äô</strong>:</p>
<p>If <span class="math inline">\(X\)</span> is a Normal random variable, <span class="math inline">\(X \sim \N(\mu, \sigma^2)\)</span>, its realization has approximately a probability of \</p>
<ul>
<li><p>For $X( ,^{2}) $
<span class="math display">\[\begin{equation*}
E\left[ X\right] =\mu \text{ and }Var\left( X\right) =\sigma ^{2}.
\end{equation*}\]</span></p></li>
<li><p>If <span class="math inline">\(a\)</span> is a number, then
<span class="math display">\[\begin{eqnarray*}
X+a &amp;\sim &amp;\N\left( \mu +a,\sigma ^{2}\right) \\
aX &amp;\sim &amp;\N\left( a\mu ,a^{2}\sigma ^{2}\right).
\end{eqnarray*}\]</span></p></li>
<li><p>If $X( ,^{2}) $ and $Y( 
,^{2}) $, and <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are  then%
<span class="math display">\[\begin{equation*}
X+Y\sim \N\left( \mu +\alpha ,\sigma ^{2}+\delta ^{2}\right).
\end{equation*}\]</span></p></li>
</ul>
<p>Locations of <span class="math inline">\(n=30\)</span> sampled values of <span class="math inline">\(X,\)</span> <span class="math inline">\(Y\)</span>, and <span class="math inline">\(X+Y\)</span> shown as tick marks under each respective density.</p>
</div>
<div id="normal-an-example" class="section level3" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Normal: an example</h3>
<!-- %\frametitle{... it's all about normality...} -->
<!-- % -->
<!-- % -->
<!-- %\begin{figure}[ptb]\centering -->
<!-- %\includegraphics[natheight=7.389in, natwidth=13.4859in, height=2.4031in, width=4.7426in]{RU_Normal.pdf}% -->
<!-- %\end{figure} -->
<!-- % -->
<!-- % -->
<!-- %% -->
<!-- % -->
</div>
</div>
<div id="the-chi-squared-distribution" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> The Chi-squared distribution</h2>
<p><span class="math inline">\(X\sim \chi ^{2}(n)\)</span> can take only values. Moreover, expected value and variance, for <span class="math inline">\(X\sim \chi ^{2}(n)\)</span>, are:</p>
<p><span class="math display">\[\begin{eqnarray*}
E\left[ X\right] &amp;=&amp;n \\
Var\left( X\right) &amp;=&amp;2n
\end{eqnarray*}\]</span></p>
<p>If <span class="math inline">\(X\sim \chi ^{2}(n)\)</span> and <span class="math inline">\(Y\sim \chi ^{2}(m)\)</span> are  then <span class="math inline">\(X+Y\sim \chi ^{2}(n+m)\)</span>.</p>
<div id="some-plots-for-the-chi-squared" class="section level3" number="5.3.1">
<h3><span class="header-section-number">5.3.1</span> Some plots for the Chi-squared</h3>
<p>Probabilities for Chi-squared distributions may be obtained from a table</p>
</div>
<div id="chi-squared-table" class="section level3" number="5.3.2">
<h3><span class="header-section-number">5.3.2</span> Chi-squared table</h3>

</div>
<div id="chi-squared-table-illustration-of-its-use" class="section level3" number="5.3.3">
<h3><span class="header-section-number">5.3.3</span> Chi-squared table (illustration of its use)</h3>
</div>
</div>
<div id="the-student-t-distribution" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> The Student-t distribution</h2>
<p><span class="math inline">\(T\sim t_{v}\,\)</span>¬†can take any value in <span class="math inline">\(\mathbb{R}\)</span>. Expected value and variance for <span class="math inline">\(T\sim t_{v}\)</span> are</p>
<p><span class="math display">\[\begin{eqnarray*}
E\left[ T\right] &amp;=&amp;0\text{, for }v&gt;1 \\
Var\left( T\right) &amp;=&amp;\frac{v}{v-2}\text{, for }v&gt;2.
\end{eqnarray*}\]</span></p>
<div id="some-student-t-distributions" class="section level3" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> Some Student-t distributions</h3>

</div>
<div id="student-t-table" class="section level3" number="5.4.2">
<h3><span class="header-section-number">5.4.2</span> Student-t table</h3>
<p><span class="math inline">\(F\sim F_{v_{1},v_{2}}\,\)</span>¬†can take only values. Expected value and variance for <span class="math inline">\(F\sim F_{v_{1},v_{2}}\)</span> (note that the order of the degrees of freedom is important!).</p>
<p><span class="math display">\[\begin{eqnarray*}
E\left[ F\right] &amp;=&amp;\frac{v_{2}}{v_{2}-2}\text{, for }v_{2}&gt;2 \\
Var\left( F\right) &amp;=&amp;\frac{2v_{2}^{2}\left( v_{1}+v_{2}-2\right) }{%
v_{1}\left( v_{2}-2\right) ^{2}\left( v_{2}-4\right) }\text{, for }v_{2}&gt;4.
\end{eqnarray*}\]</span></p>
</div>
</div>
<div id="some-f-distributions" class="section level2" number="5.5">
<h2><span class="header-section-number">5.5</span> Some F distributions</h2>
<div id="f-distribution-table-5-upper-tail" class="section level3" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> F distribution table (5% upper tail)</h3>
<p>%</p>
</div>
</div>
<div id="the-lognormal-distribution" class="section level2" number="5.6">
<h2><span class="header-section-number">5.6</span> The lognormal distribution</h2>
<p>If $Y$ $( ,^{2}) $ then%
<span class="math display">\[\begin{eqnarray*}
E\left[ Y\right] &amp;=&amp;\exp^{ \left( \mu +\frac{1}{2}\sigma ^{2}\right)} \\
Var(Y) &amp;=&amp;\exp^{ \left( 2\mu +\sigma ^{2}\right)} \left( \exp^{ \left( \sigma
^{2}\right)} -1\right).
\end{eqnarray*}\]</span></p>
Let us just see some plots‚Ä¶ more to come later‚Ä¶
<p>%</p>
</div>
<div id="exponential-distribution" class="section level2" number="5.7">
<h2><span class="header-section-number">5.7</span> Exponential distribution</h2>
<p>For <span class="math inline">\(X\sim\)</span>  we have that:</p>
<p><span class="math display">\[\begin{eqnarray}
E[X]=\int_{0}^{\infty }xf_X(x )dx= 1/\lambda &amp; \text{and} &amp;   Var(X)=\int_{0}^{\infty }x^{2}f_X(x )dx-E^{2}(X)=1/\lambda ^{2}. \nn
\end{eqnarray}\]</span></p>
</div>
<div id="transformation-of-variables" class="section level2" number="5.8">
<h2><span class="header-section-number">5.8</span> Transformation of variables</h2>
<ul>
<li>Consider a random variable <span class="math inline">\(X\)</span></li>
<li>Suppose we are interested in <span class="math inline">\(Y=\psi(X)\)</span>, where $$ is a </li>
<li>A $( x) $ (1-to-1) if there are no two numbers, <span class="math inline">\(x_{1},x_{2}\)</span> in the domain of $$ such that $( x_{1}) =( x_{2}) $ but <span class="math inline">\(x_{1}\neq x_{2}\)</span>.</li>
<li>A sufficient condition for $( x) $ to be 1-to-1 is that it be monotonically increasing (or decreasing) in <span class="math inline">\(x\)</span>.</li>
<li>Note that the  of a 1-to-1 function $y=(x) $ is a 1-to-1 function $^{-1}( y) $ such that</li>
</ul>
<p><span class="math display">\[\begin{equation*}
\psi ^{-1}\left( \psi \left( x\right) \right) =x\text{ and }\psi \left( \psi
^{-1}\left( y\right) \right) =y.
\end{equation*}\]</span></p>
<ul>
<li>To transform <span class="math inline">\(X\)</span> to <span class="math inline">\(Y\)</span>, we need to consider all the values <span class="math inline">\(x\)</span> that $%
X $ can take</li>
<li>We first transform <span class="math inline">\(x\)</span> into values <span class="math inline">\(y=\psi (x)\)</span></li>
</ul>
<div id="transformation-of-discrete-random-variables" class="section level3" number="5.8.1">
<h3><span class="header-section-number">5.8.1</span> Transformation of discrete random variables</h3>
<ul>
<li>To transform a discrete random variable <span class="math inline">\(X\)</span>, into the random variable <span class="math inline">\(Y=\psi (X)\)</span>, we transfer the probabilities for <span class="math inline">\(x\)</span> to the values $y=( x) $:</li>
</ul>
<p><span class="math display">\[\begin{equation*}
\begin{tabular}{l|cll|c}
\multicolumn{2}{l}{\emph{Probability function for }$X$} &amp;  &amp; 
\multicolumn{2}{l}{\emph{Probability function for }$X$} \\ 
&amp;  &amp;  &amp;  &amp;  \\ 
$X$ &amp; $\Pr \left(\{ X=x_{i} \}\right) =p_{i}$ &amp;  &amp; $Y$ &amp; $\Pr \left(\{
X=x_{i}  \}\right) =p_{i}$ \\ \cline{1-2}\cline{4-5}
$x_{1}$ &amp; $p_{1}$ &amp; $\qquad \Rightarrow \qquad $ &amp; $\psi (x_{1})$ &amp; $p_{1}$
\\ 
$x_{2}$ &amp; $p_{2}$ &amp;  &amp; $\psi (x_{2})$ &amp; $p_{2}$ \\ 
$x_{3}$ &amp; $p_{3}$ &amp;  &amp; $\psi (x_{3})$ &amp; $p_{3}$ \\ 
$\vdots $ &amp; $\vdots $ &amp;  &amp; $\vdots $ &amp; $\vdots $ \\ 
$x_{n}$ &amp; $p_{n}$ &amp;  &amp; $\psi (x_{n})$ &amp; $p_{n}$%
\end{tabular}%
\end{equation*}\]</span></p>
<ul>
<li>Note that this is equivalent to applying the function <span class="math inline">\(\psi \left(\cdot \right)\)</span> inside the probability statements:</li>
</ul>
<p><span class="math display">\[\begin{eqnarray*}
\Pr \left( \{ X=x_{i}  \}\right) &amp;=&amp;\Pr \left(  \{\psi \left( X\right) =\psi \left(
x_{i}\right)  \} \right) \\
&amp;=&amp;\Pr \left( \{ Y=y_{i} \} \right) \\
&amp;=&amp;p_{i}
\end{eqnarray*}\]</span></p>
</div>
<div id="transformation-of-variables-using-the-cdf" class="section level3" number="5.8.2">
<h3><span class="header-section-number">5.8.2</span> Transformation of variables using the CDF</h3>
<ul>
<li>We can use the same logic for CDF probabilities, whether the random variables are</li>
<li>Let $Y=( X) $ with $( x) $ 1-to-1 and monotone increasing. Then</li>
</ul>
<p><span class="math display">\[\begin{eqnarray*}
F_{Y}\left( y\right) &amp;=&amp;\Pr \left( \{ Y\leq y \}\right) \\
&amp;=&amp;\Pr \left( \{ \psi \left( X\right) \leq y \} \right) =\Pr \left( \{ X\leq \psi
^{-1}\left( y\right) \} \right) \\
&amp;=&amp;F_{X}\left( \psi ^{-1}\left( y\right) \right)
\end{eqnarray*}\]</span></p>
<!-- %-  True whether $X$ (and hence $Y$) are continuous or discrete random -->
<!-- %variables. -->
</div>
<div id="function-1-to-1-and-monotone-decreasing" class="section level3" number="5.8.3">
<h3><span class="header-section-number">5.8.3</span> Function 1-to-1 and monotone decreasing</h3>
<ul>
<li><p>Monotone decreasing functions work in a similar way, but require
changing of the inequality sign</p></li>
<li><p>Let $Y=( X) $ with $( x) $ 1-to-1 and
. Then
<span class="math display">\[\begin{eqnarray*}
F_{Y}\left( y\right) &amp;=&amp;\Pr \left( \{ Y\leq y \} \right) \\
&amp;=&amp;\Pr \left( \{ \psi \left( X\right) \leq y \} \right) =\Pr \left( \{ X\geq \psi
^{-1}\left( y\right) \} \right) \\
&amp;=&amp;1-F_{X}\left( \psi ^{-1}\left( y\right) \right)
\end{eqnarray*}\]</span></p></li>
</ul>
</div>
<div id="transformation-of-continuous-rv-through-pdf" class="section level3" number="5.8.4">
<h3><span class="header-section-number">5.8.4</span> Transformation of continuous RV through pdf</h3>
<ul>
<li><p>For continuous random variables, if $( x) $ 1-to-1 and
monotone , we have%
<span class="math display">\[\begin{equation*}
F_{Y}\left( y\right) =F_{X}\left( \psi ^{-1}\left( y\right) \right)
\end{equation*}\]</span></p></li>
<li><p>Notice this implies that the pdf of $Y=( X) $ must
satisfy%
<span class="math display">\[\begin{eqnarray*}
f_{Y}\left( y\right) &amp;=&amp;\frac{dF_{Y}\left( y\right) }{dy}=\frac{dF_{X}\left(
\psi ^{-1}\left( y\right) \right) }{dy} \\
&amp;=&amp;\frac{dF_{X}\left( x\right) }{dx}\times \frac{d\psi ^{-1}\left( y\right) 
}{dy}\qquad \text{{\small (chain rule)}} \\
&amp;=&amp;f_{X}\left( x\right) \times \frac{d\psi ^{-1}\left( y\right) }{dy}\qquad 
\text{{\small (derivative of CDF (of }}X\text{){\small \ is pdf)}} \\
&amp;=&amp;f_{X}\left( \psi ^{-1}\left( y\right) \right) \times \frac{d\psi
^{-1}\left( y\right) }{dy}\qquad \text{{\small (substitute }}x=\psi
^{-1}\left( y\right) \text{{\small )}}
\end{eqnarray*}\]</span></p></li>
<li><p>What happens when $( x) $ 1-to-1 and monotone ? We have%
<span class="math display">\[\begin{equation*}
F_{Y}\left( y\right) =1-F_{X}\left( \psi ^{-1}\left( y\right) \right)
\end{equation*}\]</span></p></li>
<li><p>So now the pdf of $Y=( X) $ must satisfy
<span class="math display">\[\begin{eqnarray*}
f_{Y}\left( y\right) &amp;=&amp;\frac{dF_{Y}\left( y\right) }{dy}=-\frac{%
dF_{X}\left( \psi ^{-1}\left( y\right) \right) }{dy} \\
&amp;=&amp;-f_{X}\left( \psi ^{-1}\left( y\right) \right) \times \frac{d\psi
^{-1}\left( y\right) }{dy}\qquad \text{{\small (same reasons as before)}}
\end{eqnarray*}\]</span></p></li>
<li><p>but <span class="math inline">\(\frac{d\psi ^{-1}\left( y\right) }{dy}&lt;0\)</span> since here $(
) $ is monotone decreasing, hence we can write%
<span class="math display">\[\begin{equation*}
f_{Y}\left( y\right) =f_{X}\left( \psi ^{-1}\left( y\right) \right) \times
\left\vert \frac{d\psi ^{-1}\left( y\right) }{dy}\right\vert
\end{equation*}\]</span></p></li>
<li><p>This expression (called Jacobian-formula) is valid for $( x) $ 1-to-1 and
monotone (whether increasing or decreasing)</p></li>
</ul>
</div>
<div id="example-of-transformation-using-pdf" class="section level3" number="5.8.5">
<h3><span class="header-section-number">5.8.5</span> Example of transformation using pdf</h3>
<p>More generally, for <span class="math inline">\(\alpha\in[0,1]\)</span>, the <span class="math inline">\(\alpha\)</span>-th quantile of a r.v. <span class="math inline">\(X\)</span> is the value <span class="math inline">\(x_\alpha\)</span> such that <span class="math inline">\(P(\{X \leq x_\alpha\})\geq\alpha\)</span>. If <span class="math inline">\(X\)</span> si a continuous r.v. we can set <span class="math inline">\(P(\{X \leq x_\alpha\})=\alpha\)</span> (as we did, e.g., for the lognormal).</p>
</div>
<div id="a-caveat" class="section level3" number="5.8.6">
<h3><span class="header-section-number">5.8.6</span> A caveat</h3>
<p>When <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are two random variables, we should pay attention to their transformations. For instance, let us consider
<span class="math display">\[
X\sim \mathcal{N}(\mu,\sigma^2) \quad \text{and}  \quad Y\sim Exp(\lambda).
\]</span>
Then, let‚Äôs transform <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span></p>
<ul>
<li>in a linear way: <span class="math inline">\(Z=X+Y\)</span>. We know that
<span class="math display">\[
E[Z] = E[X+Y] = E[X] + E[Y] 
\]</span>
%so we can rely on the linearity of the expected value.</li>
<li>in a nonlinear way <span class="math inline">\(W = X/Y\)</span>. One can show that</li>
</ul>
<p><span class="math display">\[\color{red} E[W] = E\left[\frac{X}{Y}\right] \neq \frac{E[X]}{E[Y]}.\]</span></p>
<!-- %so, we cannot rely on the linearity of the expected value. -->
</div>
</div>
<div id="the-big-picture" class="section level2" number="5.9">
<h2><span class="header-section-number">5.9</span> The big picture</h2>
<p>Despite exotic names, the common distributions relate to each other in intuitive and interesting ways. Several follow naturally from the Bernoulli distribution, for example.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="discreterv.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="limittheorems.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/05-continuous_rv.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Prob1-GSEM-UNIGE.pdf", "Prob1-GSEM-UNIGE.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
