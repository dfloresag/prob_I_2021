[["introduction.html", "Chapter 1 Introduction 1.1 Preliminaries 1.2 “What to expect from this Lecture?” 1.3 Appendix: Mathematical Formulae", " Chapter 1 Introduction You can write citations, too. For example, we are using the bookdown package (Xie 2020) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). 1.1 Preliminaries Data has been identified as the main commodity in our connected world of today. Generated at a breakneck pace and related to practically all of the aspects of human life, it has become a variable resource for the creation of products and services designed to improve people’s lives. For illustration, mobile devices provide enormous amounts of information of the location of users, which in turn, can help governments or big companies design better policies in what pertains mobility. Figure 1.1: the site In order to make sense of the immense amounts of Data generated every millisecond, computational tools are needed. Thankfully, in this day and age, computing power allows easy and fast manipulation of that enormous amount of information, yet it is not only by “brute force” (i.e. algorithmic power) that appropriate insights are found. Here is where mathematical theory contributes the most. The discipline that formalises the important aspects of the randomness in the data generation process and provides the tools necessary for data analysis is the field of Statistics. That said, in order to construct tools that capture these phenomena appropriately, mathematical assumptions on how the randomness/uncertainty of our data is generated. The field of mathematics that formalises randomness is the field of Probability 1.2 “What to expect from this Lecture?” In this course, we study Probability as a way to introduce Statistics. Thus we do not study Probability as a subject of interest in itself i.e. we do not develop deep probability theory using all the formal theoretical arguments, but rather we set up a few principles and methods which will be helpful to study Statistics. Hence, for the purposes of this lecture, we shall consider: Statistics: as the discipline that deals with the collection, presentation, analysis and interpretation of data. In future lectures, you will learn classical Statistical methods as well as their modern reincarnation (or “rebranding”): algorithmic tools known as Machine Learning, Deep Learning, etc. Probability as the mathematical formalisation of randomness and uncertainty the main building block of Statistical methods. keep it on 1.2.1 One intuitive illustration Before jumping into the core of the subject, I would like to make a little detour that helps illustrate intuitively the importance of Probability in everyday life. Let’s imagine you are facing a situation with an uncertain outcome, say you are attempting to gamble in a casino What are my chances of success? And sometimes, hearing you think aloud, someone in the room would attempt to quantify these chances, say, by throwing some number. “I’d say more like one out of a million.” In your mind, this number becomes an indication of the likelihood of winning your gamble, being successful in the investment. “So, you’re telling me that THERE IS A CHANCE!” jim carrey Intuitively, you understand this as the result as the result of a computation. Were you to repeat the experiment (gamble, investment) your chances of success results from a ratio between the number of times you are successful, versus the number of attempts. \\[\\text{my chances} = \\frac{\\text{number of times I succeed}}{\\text{number of times I fail}}\\] In a bit of an abuse of language, this value, constitutes the probability of success. When it’s small, success is very unlikely, but if it is large (or at least closer to 1), the event seems more likely Probability constitutes then the measure of the “likelihood” of an event or random outcome. Hence, we can measure Uncertainty units of , which is the currency of statistics. “In this world there is nothing certain but death and taxes.” - Benjamin Franklin 1.2.1.1 Another illustration: Stock price evolution stonks Let us see how a simple probabilistic model can help us characterise the uncertainty of the Stock price of an asset. With probability \\(p=1/2\\) the stock price moves up of a factor \\(u\\), and with probability \\(1-p\\) the price moves down of a factor \\(d\\). We denote the price at time \\(t_1\\) by $uS_0 $ if the price goes up, and by $dS_0 $ if the price goes down. Let us set \\(S_0=1\\), \\(u=2\\) and \\(d=1/2\\). Can we say something about the price at time \\(t_2\\)? The price evolution is represented by a tree: Insert illustration or animation 1.2.1.2 Example: Quanta I’m not sure about this example Probability models are the basis for quantum physics: they characterize the uncertainty of properties of single energy quanta'' emitted by aperfect radiator\" with a given temperature (\\(T\\)). Specifically, recall the famous Einstein’s equation \\[\\boxed{\\mathcal{E} = m c^2}\\] which expresses the energy \\(\\mathcal{E}\\) in terms of the mass and \\(c\\), the speed of light. Moreover, consider the geometric energy mean defined by \\({\\mathcal{E}_G} = c_0 k_B T\\), where \\(c_0 \\approx 2.134\\) and \\(k_B\\) is Boltzmann’s constant. Thus, one can define the random quantity \\[W = \\frac{\\mathcal{E}}{{\\mathcal{E}_G}},\\] which is called quantum mass ratio. The random behaviour of \\(W\\) can be described by a probability density function: Insert Illustration or animation of the quantum mass ratio. 1.3 Appendix: Mathematical Formulae Probability theory is a mathematical tool. Hence, it is important to review some elemental mathematical concepts. Here are some of the formulae that we will use throughout the course. 1.3.1 Powers and Logarithms \\(a^m \\times a^n = a^{m+n}\\); \\((a^n)^m = a^{m \\times n}\\); \\(\\ln(\\exp^{a}) = a\\); \\(a=\\ln(\\exp^{a}) = \\ln(e^a)\\); \\(\\ln(a^n) = n \\times \\ln a\\); \\(\\ln (a \\times b) = \\ln (a) + \\ln (b)\\); 1.3.2 Differentiation derivatives will also play a pivotal role. For instance: Derivative of the \\(x\\) to the power \\(n\\), \\(f(x)= x^n\\) \\[\\frac{d x^n}{dx} = n \\cdot x^{n-1}\\] Derivative of the exponential function \\(f(x) = \\exp(x)\\) \\[\\frac{d \\exp^{x}}{dx} = \\exp^{x}\\] Derivative of the natural logarithm \\(f(x) = \\ln(x)\\) \\[ \\frac{d \\ln({x})}{dx} = \\frac{1}{x}\\] Moreover, we will make use of some fundamental rules, such as: 1.3.2.1 Product rule: \\[\\begin{align} \\frac{d [f(x)\\cdot g(x)]}{dx} &amp;= \\frac{df(x)}{dx} g(x) + \\frac{dg(x)}{dx} f(x) \\\\ &amp;= f&#39;(x) g(x)+ f(x) g&#39;(x) \\end{align}\\] 1.3.2.2 Chain rule \\[\\frac{d f[g(x)]}{dx} = (f\\circ g)&#39;(x) = f&#39;[g(x)] \\cdot g&#39;(x)\\] 1.3.3 Integration Integrals will be crucial in many tasks. For instance, recall that integration is linear over the sum, i.e. \\(\\forall c, d \\in \\mathbb{R}\\) \\[\\int_{a}^{b} \\left[c \\times f(x) + d \\times g(x) \\right]dx = c \\times \\int_{a}^{b} f(x) dx + d \\times \\int_{a}^{b} g(x) dx; \\] If \\(f(x) \\geq 0, \\forall x \\in \\mathbb{R}\\), then \\[\\int_{\\mathbb{R}} f(x) dx \\geq 0.\\] For a continuous function \\(f(x)\\), the indefinite integral is \\[\\int f(x) dx = F(x) + \\text{const}\\] while the definite integral is \\[F(b)-F(a)= \\int_{a}^{b} f(x) dx, \\quad b \\geq a.\\] 1.3.4 Sums Besides integrals we are also going to use sums: Sums are denoted with a \\(\\Sigma\\) operator and an index \\(i\\), as in: \\[\\sum_{i=1}^{n} X_{i} = X_1 + X_2 +....+ X_n,\\] - Moreover, for every \\(\\alpha_i \\in \\mathbb{R}\\), \\[\\sum_{i=1}^{n} \\alpha_i X_{i} = \\alpha_1 X_1 + \\alpha_2 X_2 +....+ \\alpha_n X_n;\\] A double sum is a sum operated over two indices. For instance, \\[\\sum_{i=1}^{n} \\sum_{j=1}^{m} x_{i}y_{j} = x_1y_1 + x_1 y_2 +... +x_2y_1+ x_2y_2 + \\dots\\] by carefully arranging the terms in the sum, we can stablish the following identity: \\[\\begin{align} \\sum_{i=1}^{n} \\sum_{j=1}^{m} x_{i}y_{j} &amp;= x_1y_1 + x_1 y_2 +... +x_2y_1+ x_2y_2 + \\dots \\\\ &amp;= \\left(\\sum_{i=1}^{n} x_i\\right) y_1 + \\left(\\sum_{i=1}^{n} x_i\\right) y_2 + \\dots + \\left(\\sum_{i=1}^{n} x_i\\right) y_m \\\\ &amp;= \\sum_{i=1}^{n} x_i \\sum_{j=1}^{m} y_j. \\end{align}\\] 1.3.5 Combinatorics Finally, we also rely on some combinatorial formulas. Specifically, 1.3.5.1 Factorial \\[ n! = n \\times (n-1) \\times (n-2) \\times \\dots \\times 1;\\] where \\(0! =1\\), by definition; - Binomial coefficient, for \\(n \\geq k\\) \\[\\binom n k =\\frac{n!}{k!(n-k)!}{\\color{blue}{=C^{k}_n}}\\] which is helpful to express the Binomial Theorem \\[(x+y)^n = {n \\choose 0}x^n y^0 + {n \\choose 1}x^{n-1}y^1 + \\cdots + {n \\choose n-1}x^1 y^{n-1} + {n \\choose n}x^0 y^n;\\] or equivalently, making use of the sum notation, \\[(x+y)^n = \\sum_{k=0}^n {n \\choose k}x^{n-k}y^k = \\sum_{k=0}^n {n \\choose k}x^{k}y^{n-k}.\\] Example 1.1 Let us compute: for \\(n=1\\) we have \\[\\begin{align} (x+y)^1 &amp;= {1 \\choose 0}x^1 y^0 + {2 \\choose 1}x^{1}y^1 + {2 \\choose 0}x^0 y^{2}\\\\ &amp;= x^2 + 2 x y + y^{2} \\end{align}\\] for \\(n=2\\) we have \\[\\begin{align} (x+y)^2 &amp;= {2 \\choose 0}x^2 y^0 + {2 \\choose 1}x^{1}y^1 + {2 \\choose 2}x^0 y^{2} \\\\ &amp;= x^2 + 2 x y + y^{2} \\end{align}\\] for \\(n=3\\) we have \\[\\begin{align} (x+y)^3 &amp;= {3 \\choose 0}x^3 y^0 + {3 \\choose 1}x^{2}y^1 + \\cdots + {3 \\choose 2}x^1 y^{2} + {3 \\choose 3}x^0 y^3 \\\\ &amp;= y^3 + 3xy^2 + 3x^2y+x^3 \\end{align}\\] How many ways can we select \\(3\\) presents among the \\(5\\) available presents (see figure below)? Assume the order does not matter! \\(5!\\) gives you the total \\(\\#\\) of possible choices when you can select 5 presents (so-called ``permutations’’, see next slides); If you’re going to select \\(3\\) presents from the list, then you have \\((5-3)\\) presents that you’re not going to select. Therefore, you need to divide out the \\((5-3)!\\) different ways you can order the presents you are not going to select from the \\(5!\\) possible choices of all presents. In other words you have \\(5! / (5-3) !\\) ways to select and order the 3 presents; Finally, remember you don’t care about the order in which you select the \\(3\\) presents. So, in how many ways can you select \\(3\\) presents from the \\(n\\) available ones? The problem is the same as in point 1. aboveexcept that now you don’t care about the order of the \\(3\\) presents, and therefore you also need to divide out the \\(3!\\) different ways you can order the presents. … so, in formula, you have \\[\\frac{5!/(5-3)!}{3!}\\] ways to select the \\(3\\) presents: \\[\\frac{5!/(5-3)!}{3!}= \\frac{5!}{3!2!} = \\binom 5 3 = C_5^3.\\] This gives you the total \\(\\#\\) of possible ways to select the \\(3\\) presents when the order does not matter. As a recommendation, redo the exercise assuming you can select 2 presents from 3 available presents (like for instance F,L,R)… Remark. Permutations: How many different ways can we combine \\(n\\) objects? In the 1st place: \\(n\\) possibilities In the 2nd place: \\((n-1)\\) possibilities … Finally, \\(1\\) possibility Thus, in total we have \\(n\\times(n-1)\\times(n-2)\\times...\\times1 = n!\\) Example 1.2 How many ways can Aline, Brigitte and Carmen seat on 3 spots, from left to right? Possible outcomes: \\[ (A, B, C), (A, C, B), (B, A, C), (B, C, A), (C, A, B), (C, B, A) \\] Total \\(\\#\\) of permutations: \\(N = 6 = 3 \\times 2 \\times 1 = 3!\\) Remark. [continued] Combinations: How many ways can we select \\(k\\) objects among \\(n\\)? To answer this question, we proceed as follows: How many ways can we combine \\(k\\) objects among \\(n\\)? In the 1st place: \\(n\\) In the 2nd place: \\((n-1)\\) …. In the \\(k\\)-th place: \\((n-k+1)\\) We have \\(k!\\) ways to permute the \\(k\\) objects that we selected The number of possibilities (without considering the order) is: \\[\\frac{n!/(n-k)!}{k!} = \\frac{n!}{k!(n-k)!}{\\color{gray}{=C^{k}_n}}\\] For the Problem Set \\(2\\), you will have to make use of \\(C^{k}_n\\) in Ex2-Ex3-Ex5. Indeed, to compute the probability for an event \\(E\\), will have to make use of the formula \\[\\begin{equation} \\label{Eq: PE} P(E)=\\dfrac{\\text{number of cases in E}}{\\text{number of possible cases}}. \\end{equation}\\] This is a first intuitive definition of probability, which we will justify in the next lecture; see Lecture 1, slide 28. For the time being, let us say that the combinatorial calculus will be needed to express both the quantities (numerator and denominator) in (). Finally, the following limits will be crucial in many tasks: \\[\\lim_{n \\to \\infty} \\sum_{i=1}^n x_i = \\sum_{i=1 }^\\infty x_i \\nonumber\\] \\[ e^x = \\lim_{n \\rightarrow \\infty} \\left(1 + \\frac{x}{n}\\right)^n \\nonumber\\] for \\(\\alpha &gt;0\\) \\[\\lim_{x \\to \\infty} {\\alpha e^{-\\alpha x}} = 0 \\nonumber\\] \\[e^x = \\sum_{i = 0}^{\\infty} {x^i \\over i!} = 1 + x + {x^2 \\over 2!} + {x^3 \\over 3!} + {x^4 \\over 4!} + \\dots\\] "]]
