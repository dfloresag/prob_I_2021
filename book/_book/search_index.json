[["numericalmethods.html", "Chapter 8 Numerical Methods 8.1 Introduction to simulation 8.2 Simulation procedure 8.3 Simulation in R 8.4 Coin tossing 8.5 Summarizing", " Chapter 8 Numerical Methods 8.1 Introduction to simulation \\(\\Rightarrow\\) Well, actually, the first method that comes to our mind (see Lecture 3) consists in assuming (quite reasonably) that the \\(52!\\) permutations of the cards are equally likely. Then, we ``count’’ the number of favorable games … Unfortunately, the of this criterion seems quite demanding: \\(52!\\) it is a huge number (even the combinatronics seems messy!!!) So, we should, sadly, conclude that the derivation of the required probability is hardly tractable from a strict mathematical stand point….However, we can decide to ``drop ’’ the rigorous mathematical treatment and invoke an approach which is pretty standard in the applied science: we make use of an to gain insights and further understanding. For instance, in our case of card game, the consists in playing a (very) large number of games and count the numbers of favorable events (we win). So, after the execution of \\(n\\) (say) games we will be able to set: \\[X_i = \\left\\{\\begin{array}{ll} 1&amp; \\mbox{ if the $i$-th game is a victory}\\\\ 0 &amp; \\mbox{ else} \\end{array}\\right.\\] where the variables \\(X_i\\), for \\(i=1,...n\\) are random variables, each having a Bernoulli distribution such that \\[E(X_i) = P(\\text{win the card game}) = p.\\] Now, invoking the WLLN, we have that \\[\\bar{X}_n = \\frac{\\sum_{i=1}^n X_i}{n} = \\frac{\\text{# of favorable games}}{\\text{# of total games played}}\\] converges, as \\(n \\to \\infty\\), in probability to \\(p\\), i.e. the probability of winning. In words, we can claim that after a large number of games the proportion of games that we win can be reasonably applied to get an estimate of \\(p\\). 8.2 Simulation procedure The remaining issue is that we have typically no time to play such a big number of games, so we let a computer play. With this aim: we should generate values from a random variable having \\(U(0,1)\\) distribution: these values are called random numbers. Starting from a \\(U \\sim U(0,1)\\) distribution, we can in principle simulate any random variable having a CDF, by means of the \\(F^{-1}\\) transformation % (see tutorial, \\(Y=F^{-1}(U)\\)). Remark. In fact, the computer makes use of the so called : an algorithm produces a sequence of numbers which are (only) pseudo- random. Namely, the generator yields a sequence of numbers that, PRACTICALLY, is VERY SIMILAR to a sample drawn form \\(U(0,1)\\). The way in which this algorithm works is behind the scope of this course: let’s simply say that you can use the statistical software to achieve the task. 8.3 Simulation in R For instance, a well-know (freely available software) is R: and 1 realization of a r.v \\(B(10, 0.5)\\) can be obtained as: and 5 realization of a r.v.’s \\(B(10, 0.5)\\) can be obtained as: and 1 realization of a r.v.’s \\(U(0, 1)\\) can be obtained as: and 5 realization of a r.v.’s \\(U(0, 1)\\) can be obtained as: 8.4 Coin tossing A computer cannot toss a coin, but it can generate Bernoulli random numbers… …so that we can simulate the outcomes of fair coin \\(P(H)=P(T)=0.5\\) …or (exotic case) we can simulate the outcomes of unbalanced coin \\(P(T)=0.8\\) …or (even more exotic) we can simulate the outcomes of unbalanced coin \\(P(H)=P(T)=0.45\\) and probability of remaining on its edge \\(0.1\\) 8.5 Summarizing Remark. We can make use of the computer power of calculus to shed light on some probabilistic questions.\\ The use of the computer power of calculus and the theory of probability are not mutually exclusive. Rather, I firmly believe that they complement each other: using the computer without any underpinning theoretical development is pointless, while the development of probability theory can strongly benefit from the use of computer power of calculus. "]]
