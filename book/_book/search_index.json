[["settheory.html", "Chapter 2 Elements of Set Theory for Probability 2.1 Definitions 2.2 Some definitions from set theory 2.3 The Venn diagram 2.4 Countable and Uncountable sets 2.5 De Morgan’s Laws: 2.6 De Morgan’s Theorem 2.7 Back to the events 2.8 Some references", " Chapter 2 Elements of Set Theory for Probability 2.1 Definitions In order to develop the Probability theory of this course we are going to need also some elements of set theory. To start our journey, let us introduce some definitions in Probability. Definition 2.1 A Random Experiment is a process that can result in two or more different outcomes with uncertainty as to which will be observed. Definition 2.2 An Event is an uncertain outcome of a random experiment. An event can be: Elementary: it includes only one particular outcome of the experiment Composite: it includes more than one elementary outcome in the possible sets of outcomes. Definition 2.3 The Sample Space is the complete listing of the elementary events that can occur in a random experiment. We will denote the sample space by \\(S\\). Example 2.1 (A simple card game) When playing with a full deck of cards, we can characterise drawing a particular card as a random experiment, where we can identify a set of events and the sample space: Example 2.2 (Flipping Coins) Flipping a set of two coins can be characterised as another random experiment. In this case, let us denote the outcomes for each coin are \\(H\\) for Head and \\(T\\) for Tail. Hence, the sample space of the experiment “flipping two coins” contains the following four points: \\[S = \\{ (HH),(HT),(TH),(TT) \\}.\\] Example 2.3 (Time on your phone) Say you are interested in measuring the time of your life spent on your phone. The measure of the time (in hours) can be considered as the outcome of a random experiment, and every measure of the time, an event. When you take a measure, you will be counting fractions of the hour spent on your phone (e.g. 20 minutes = 1/3 h). Therefore, the possible outcomes of this experiment are are durations measured in fractions ranging from 0 to infinity. Hence, the sample space consists of all nonnegative real numbers: \\[ S = \\{x: 0 \\leq x &lt; \\infty \\}\\] or, equivalently, \\(S\\equiv \\mathbb{R}^+\\). 2.2 Some definitions from set theory The following definitions from set theory will be useful to deal with events. Definition 2.4 If every element of a set \\(A\\) is also an element of a set \\(B\\), then \\(A\\) is a of \\(B\\). We write this as : \\[A \\subset B\\] and we read it as “\\(A\\) is contained in \\(B\\)” Definition 2.5 Two sets \\(A\\) and \\(B\\) are said to be equal if \\[A \\subset B \\text{ and } B \\subset A;\\] Definition 2.6 If a set \\(A\\) contains no points, it will be called the null set, or empty set, and it is typically denoted by \\(\\varnothing\\). 2.3 The Venn diagram Figure 2.1: source: Tenso Graphics The Venn diagram is an elementary schematic representation of sets and helps displaying their properties. As you might remember from your elementary classes, a Venn diagram represents a set with a closed figure, and its elements with some dots. To be even more abstract, most of the times, the dots are scraped and it is assumed that the set elements are in the surface contained by the figure. They are very useful to illustrate inclusion and equality as well as more abstract notions. A generic Venn Diagram of inclusion and equality 2.3.1 Sample Space and Events By definition, an event or several events, constitute subset of the sample space. This can be represented in a Venn Diagram with a figure enclosed within the Sample Space. Figure 2.2: source: Tenso Graphics 2.3.2 Exclusive and Non-Exclusive Events Two events are mutually exclusive is they cannot occur jointly. This is represented by two separate enclosed surfaces within the sample space. For illustration, consider our simple card game example. The event “drawing a King” and “drawing a Queen” are mutually exclusive, as they can’t happen at the same time. Figure 2.3: Two mutually exclusive events chart: Events of King and Queen Events that are not mutually exclusive have a shared area, which in set theory constitutes an intersection and gets shown in a Venn diagram by two colliding figures. Coming back to our example with the card game, consider the events “drawing a King” and “drawing a Heart.” Here there is intersection, as one can obtain a King of Hearts. Figure 2.4: Two Non-mutually exclusive events Example : chart Events of King and Heart. 2.3.3 Union and Intersection of Events The union of the events \\(A\\) and \\(B\\) is the event which occurs when either \\(A\\) or \\(B\\) occurs: \\(A \\cup B\\). In a Venn diagram, we can illustrate this by shading the area enclosed by both sets. Insert chart union –&gt; The intersection of the events \\(A\\) and \\(B\\) is the event which occurs when both \\(A\\) and \\(B\\) occur: \\(A \\cap B\\). In a Venn diagram, we can illustrate this by shading the area shared by both sets. Insert chart intersection 2.3.4 Complement The complement of an event \\(A\\) is the event which occurs when \\(A\\) does not occur: \\(A^{c}\\) (or \\(\\overline{A}\\)). A Venn diagram illustrates this by shading the area outside the set. Figure 2.5: source: Tenso Graphics Let \\(S\\) be the complete set of all possible events, i.e. the Sample Space. Then, \\(A^c\\) can be written as: \\[A^c = S \\setminus A = S-A.\\] and is such that \\[A \\cup A^c = S.\\] 2.3.5 Some laws of Let \\(A\\), \\(B\\), and \\(D\\) be sets. The following laws hold: Commutative laws: Union and Intersection of sets are commutative, i.e. they produce the same outcome irrespective of the order in which the sets are written. \\[\\begin{eqnarray*} A \\cup B = B \\cup A \\\\ A \\cap B = B \\cap A \\end{eqnarray*}\\] Associative laws: Union and Intersection of more than two sets operate irrespective of the order. \\[\\begin{eqnarray*} A \\cup (B \\cup D) = (A \\cup B) \\cup D \\\\ A \\cap (B \\cap D) = (A \\cap B) \\cap D \\end{eqnarray*}\\] Distributive laws The intersection is distributive with respect to the union, i.e. the intersection between a set (\\(A\\)) and the union of two other sets (\\(B\\) and \\(D\\)) is the union of the intersections. \\[ A \\cap (B \\cup D) = (A \\cap B) \\cup (A\\cap D)\\] The union is distributive with respect to the intersection, i.e. the union between a set (\\(A\\)) and an intersection of two others is the intersection of the unions. \\[A \\cup (B \\cap D) = (A\\cup B) \\cap (A \\cup D)\\] insert illustration We can use Venn Diagrams to illustrate these laws. Consider Exercise 2.1 Let \\(A\\) and \\(B\\) be two sets. Use Venn diagrams to represent: \\(\\overline{A\\cap B}\\) \\(B-A\\) 2.4 Countable and Uncountable sets Events can be represented by means of sets and sets can be either countable or uncountable. In mathematics, a countable set is a set with the same cardinality (number of elements) as some subset of the set of natural numbers \\(\\mathbb{N}= \\{0, 1, 2, 3, \\dots \\}\\). For illustration, a cow herd is a countable set, as you can have 0, 1, 2, 3, … cows in your herd. illustrations with cows A countable set can be countably finite (your cow herd) or countably infinite. Whether finite or infinite, the elements of a countable set can always be counted one at a time and, although the counting may never finish, every element of the set is associated with a natural number. Roughly speaking one can count the elements of the set using \\(1,2,3,..\\) G. Cantor introduced the term countable set, contrasting sets that are countable with those that are **uncountable} (i.e., nonenumerable or nondenumerable). Example 2.4 (An illustration of a Countable Set) Let’s come back to our example with the deck of cards and the event. The follwing events can be considered countably finite sets. Exercise 2.2 (An illustration of an Uncountable Set) and using the definition of \\(A\\) and \\(B\\) compute: \\(A^c\\) \\(B^c\\) \\(B^c \\cup A\\) \\(B^c \\cup A^c\\) \\(A \\cup B\\) \\(A \\cap B\\) \\(B \\cup A^c\\) \\(A^c \\cup A\\) Exercise 2.3 (flipping coins again) Let us consider the experiment where we flip two coins. For each coin we have \\(H\\) for Head and \\(T\\) for Tail. Remember that the sample space contains the following four points add reference here \\[ S = \\{ (HH),(HT),(TH),(TT) \\}.\\] Then, let us consider the events: \\(A= H\\) is obtained at least once = \\(\\Big\\{ (HH),(HT),(TH) \\Big\\}\\) \\(B=\\) the second toss yields \\(T\\) = \\(\\Big\\{ (HT),(TT) \\Big\\}\\) and using the definitions of \\(A\\) and \\(B\\) compute: \\(A^c\\) \\(B^c\\) \\(B^c \\cup A\\) \\(A \\cup B\\) \\(A \\cap B\\) \\(B \\cup A^c\\) Proposition 2.1 Let \\(A\\) be a set in \\(S\\) and let \\(\\varnothing\\) denote the empty set1. The following relations hold: \\(A \\cap S = A\\); \\(A \\cup S = S\\); \\(A \\cap \\varnothing = \\varnothing\\); \\(A \\cup \\varnothing = A\\); \\(A \\cap A^c = \\varnothing\\); \\(A \\cup A^c = S\\); \\(A \\cap A = A\\); \\(A \\cup A = A\\); Exercise 2.4 Use Venn Diagrams to illustarte these relationships The above relations are helpful to define some other relations between sets/events. Example 2.5 Let \\(A\\) and \\(B\\) be two sets in \\(S\\). Then we have: \\[B = (B \\cap A) \\cup (B \\cap A^c).\\] To check it, we can proceed as follows: \\[\\begin{eqnarray*} B &amp; = &amp; S \\cap B \\\\ &amp; = &amp; (A \\cup A^c) \\cap B \\\\ &amp; = &amp; (B \\cap A) \\cup (B \\cap A^c). \\end{eqnarray*}\\] That concludes the argument. 2.5 De Morgan’s Laws: 2.5.1 First Law Let \\(A\\) and \\(B\\) be two sets in \\(S\\). Then: \\[\\begin{eqnarray} (A\\cap B)^{c} =A^c \\cup B^c, \\end{eqnarray}\\] where: Left hand side: \\((A\\cap B)^{c}\\) represents the set of all elements that are not both \\(A\\) and \\(B\\); Right hand side: \\(A^c \\cup B^c\\) represents all elements that are not \\(A\\) (namely they are \\(A^c\\)) and not \\(B\\) either (namely they are \\(B^c\\)) \\(\\Rightarrow\\) set of all elements that are not both \\(A\\) and \\(B\\). 2.5.2 Second Law Let \\(A\\) and \\(B\\) be two sets in \\(S\\). Then: \\[\\begin{eqnarray} (A\\cup B)^{c} =A^c \\cap B^c, \\nn \\end{eqnarray}\\] where: Left hand side: \\((A\\cup B)^{c}\\) represents the set of all elements that are neither \\(A\\) nor \\(B\\); Right hand side:\\(\\color{blue}{A^c \\cap B^c}\\) represents the intersection of all elements that are not \\(A\\) (namely they are \\(A^c\\)) and not \\(B\\) either (namely they are \\(B^c\\)) \\(\\Rightarrow\\) set of all elements that are neither \\(A\\) nor \\(B\\). 2.6 De Morgan’s Theorem More generally, we can consider unions and intersections of many (countable) sets. So, we state the general results: Theorem 2.1 (De Morgan’s Theorem) Let \\(\\mathbb{N}\\) be the set of natural number and \\(\\{A_{i}\\}\\) a collection (indexed by \\(i \\in \\mathbb{N}\\)) of subsets of \\(S\\). Then: \\[\\begin{eqnarray} \\overline{\\bigcup_{i \\in \\mathbb{N}} A_i} &amp;=&amp; \\bigcap_{i \\in \\mathbb{N}} \\overline{A}_i; \\end{eqnarray}\\] \\[\\begin{eqnarray} \\overline{\\bigcap_{i \\in \\mathbb{N}} A_i} &amp;=&amp; \\bigcup_{i \\in \\mathbb{N}} \\overline{A}_i. \\end{eqnarray}\\] 2.7 Back to the events Our primary interest will be not in events per se, but it will be in the probability that an event does or does not happen. Intuitively, the probability of an event is the number associated to the event: \\[\\text{event} \\rightarrow \\text{pr(event)}\\] such that: the probability is positive or more generally non-negative (it can be zero); the \\(\\text{pr}(S)=1\\) (remember, \\(S\\) is the sample space) and \\(\\text{pr}(\\varnothing)=0\\); the probability of two (or more) mutually exclusive events is the sum of the probabilities of each event. In many experiments, it is natural to assume that all outcomes in the sample space (\\(S\\)) are equally likely to occur. That is, consider an experiment whose sample space is a finite set, say, \\(S=\\{1,2,3,...N\\}\\). Then, it is often natural to assume that \\[P(\\{1\\})=P(\\{2\\})=...=P(\\{N\\})\\] or equivalently \\(P(\\{i\\})= 1/N\\), for \\(i=1,2,...,N\\). Now, if we define a composite event \\(A\\), there exist \\(N_A\\) realizations having the same likelihood (namely, the have the same probability) in the event \\(A\\), so \\[\\boxed{P(A)=\\frac{N_A}{N}=\\frac{\\mbox{# of favorable outcomes}}{\\mbox{total # of outcomes}}=\\frac{\\mbox{# of outcomes in $A$}}{\\mbox{# of outcomes in $S$}}}\\] where the notation $# $ means “number.” Example 2.6 We roll a fair die and we define the event \\[A=\\text{the outcome is an even number}=\\{2,4,6\\}.\\] What is the probability of \\(A\\)? First, we identify the sample space as \\[S=\\{1,2,3,4,5,6\\}.\\] Then, we have that \\[P(A)=\\frac{N_A}{N} = \\frac{\\mbox{3 favorable outcomes}}{\\mbox{6 total outcomes}} = \\frac{1}{2}. \\] Building on the intuition gained in the last example (see boxed formula), we state a first informal definition of probability. Specifically, one way of defining the probability of an event is in terms of . Definition 2.7 # [Informal] Suppose that an experiment, whose sample space is \\(S\\), is repeatedly performed under exactly the same conditions. For each event, say \\(A\\), of the sample space, we define \\(n(A)\\) to be the number of times in the first \\(n\\) repetitions of the experiment that the event \\(A\\) occurs. Then, \\(P(A)\\), namely the probability of the event \\(A\\), is defined as: \\[ P(A)=\\lim_{n \\to \\infty} \\frac{n(A)}{n}, \\] that is \\(P(A)\\) is defined as the limiting proportion/frequency of time that \\(A\\) occurs: it is the limit of relative frequency of \\(A\\). Example 2.7 # [Tossing a well-balanced coin] In tossing a well-balanced coin, there are 2 mutually exclusive equiprobrable outcomes: H and T. Let \\(A\\) be the event of head (H). Since the coin is fair, we have \\(P(A)=1/2\\). To confirm this intuition/conjecture we can toss the coin a large number of times (each under identical conditions) and count the times we have H. Let \\(n\\) be the while \\(n(A)\\) is the . Then, the relative frequency: \\[ \\lim_{n \\to \\infty} \\frac{n(A)}{n}, \\] converges to \\(P(A)\\). So, \\[ P(A) \\sim \\frac{n(A)}{n}, \\quad \\text{for large $n$}. \\] Clearly, \\[0 \\leq n(A) \\leq n, \\quad \\text{so} \\quad 0 \\leq P(A) \\leq 1.\\] Thus, we say that the probability is a set function (it is defined on sets) and it associates to each set/event a number between zero and one. Remark. One can provide a more rigorous definition of probability, as a real-valued function which defines a mapping between sets/events and the interval \\([0,1]\\). To achieve this goal one needs the concept of sigma-algebra (which represents the domain of the probability), but we do not pursue with that—at the cost of losing the mathematical rigour of the next slide!! To express the probability, we need to impose some additional conditions, that we are going to call axioms. We here briefly state the ideas, then we will formalize them: When we define the probability we would want the have a domain such that it includes the sample space \\(S\\) and \\(P(S)=1\\). Moreover, for the sake of completeness, if \\(A\\) is an event and we can talk about the probability that \\(A\\) happens, then it is suitable for us that \\(A^c\\) is also an event, so that we can talk about the probability that \\(A\\) does not happen. Similarly, if \\(A_1\\) and \\(A_2\\) are two events (so we can say something about their probability of happening), so we should be able to say something about the probability of the event \\(A_1 \\cup A_2\\). 2.8 Some references The interested Student can find some additional info in the books by (Rozanov 2013) and (Hogg, McKean, and Craig 2019). A set is called empty if it contains no elements.↩︎ "]]
