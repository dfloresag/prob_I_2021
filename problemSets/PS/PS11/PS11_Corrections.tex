\documentclass[12pt,thmsa]{article}\usepackage[]{graphicx}\usepackage[]{color}
% maxwidth is the original width if it is less than linewidth
% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}
\usepackage[french,english]{babel}
\usepackage[ansinew]{inputenc}
\usepackage[T1,OT1]{fontenc}
\usepackage{graphicx}
\usepackage{amsmath,amssymb,listings}
\usepackage{alltt,algorithmic,algorithm}
\usepackage{multicol}
\usepackage{cite}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{array}
\usepackage{amsfonts}
\usepackage{latexsym}
\usepackage{epsf}
\usepackage{umlaute}
\usepackage{setspace}
\usepackage{amsthm}
\usepackage{enumerate}


\setlength{\textwidth}{160mm}
\setlength{\textheight}{230mm}
\setlength{\oddsidemargin}{-5mm}
\setlength{\topmargin}{-10mm}

% to get rid of the numbers in the bibliography:
\makeatletter
\def\@biblabel#1{}
\makeatother



\title{Assignement 11}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}


\noindent \textsc{University of Geneva}     \hfill \textsc{Bachelor in Economics and Management} \\
\textbf{Probability 1}                      \hfill \textsc{Bachelor in International Relations} \\
Dr. Daniel \textsc{Flores Agreda}                 \hfill Spring 2021  \\
ASSIGNMENT 11



\noindent
\makebox[\linewidth]{\rule{\textwidth}{0.4pt}}\\[1.5ex]




\addtocounter{section}{1}
\section*{Exercise \thesection:}

Let $X$ be the yearly income of an employee and $E(X)=50'000$ its expectation.
\begin{enumerate}
  \item We use the Markov inequality to find a upper bound for the pourcentage $p$ of the incomes bigger or equal to 80'000 \$:
  \begin{equation*}
P(X \geq 80'000)\leq \frac{50'000}{80'000}=\frac{5}{8}=0.625.
  \end{equation*}
  Less than 62.5\% of the employees of the bank earn more than 80'000 \$.
  \item We know now the standard error of $X$  and this allow us to define a more accurate upper bound using the Chebychev inequality:
 \begin{eqnarray*}
 P(X\geq 80'000)&=& P(X-50'000\geq 30'000) \\
 &\leq&P(\vert X- 50'000\vert \geq 30'000)\leq \frac{10'000^2}{30'000^2}=\frac{1}{9} \approx 0.11.
 \end{eqnarray*}
\end{enumerate}




\section*{Exercise 2:}

Let $X_i$ be a Bernouilli random variable associated to the ith elector such that:
$$
X_i =\left\{
\begin{array}{ll}
1 & \mbox{if }i \mbox{ vote for Barack},\\
0 & \mbox{otherwise}.
\end{array}
\right.
$$
Let $\displaystyle Y=\sum_{i=1}^{1'200} X_i$ the number of voters for Barack. $Y\sim \mathrm B( 1200, p)$ We want to find $p$ such that:
$$
P\{Y\geq 600\} = 0.95.
$$
We have $E(Y)=1'200\cdot p$, $Var(Y)=1'200\cdot p(1-p)$ and
\begin{eqnarray*}
P (Y\geq 600) &=& P\left(\frac{Y-1'200 \cdot p}{\sqrt{1'200\cdot p(1-p)}} \geq \frac{600
- 1'200\cdot p}{\sqrt{1'200\cdot p(1-p)}}\right)   \\
&=& 1 -P\left(\frac{Y-1'200\cdot p}{\sqrt{1'200\cdot p(1-p)}} < \frac{600
- 1'200\cdot p}{\sqrt{1'200\cdot p(1-p)}}\right).
\end{eqnarray*}

Using the Central limit theorem:
$$
P\left(\frac{Y-1'200\cdot p}{\sqrt{1'200p(1-p)}} < \frac{600 -
1'200\cdot p}{\sqrt{1'200\cdot p(1-p)}}\right) \approx \Phi\left(\frac{600 -
1'200\cdot p}{\sqrt{1'200\cdot p(1-p)}}\right).
$$
We look then for $p$ such that:
$$
\Phi\left(\frac{600 - 1'200\cdot p}{\sqrt{1'200\cdot p(1-p)}}\right) = 0.05
$$
so:
$$
\frac{600 - 1'200\cdot p}{\sqrt{1'200\cdot p(1-p)}} = -1.645
$$
and we find $p \approx 0.52.$




\section*{Exercise 3:}

Let $ X $ be the number of registrations, it is a Poisson random variable with parameter $ \lambda = 100 $. We search
$$
P(X \geq 120) = e^{-100}\sum_{x=120}^\infty \frac{100^x}{x!} = 1 -
e^{-100}\sum_{x=0}^{119} \frac{100^x}{x!}.
$$
The numerical calculation of such an expression is not easy.

We can use the property that a Poisson random variable with parameter 100 can be seen as the sum of 100 independent random variables of Poisson with parameter 1. We can thus use the limit central theorem. In other words, X, which follows a distribution of $Poisson(\lambda = 100)$ will also follow approximately a normal distribution of parameters.

$$
\mu = \text{E}(X) = 100 \cdot 1 = 100 \quad \mbox{ and} \quad \sigma^2 =
\text{var}(X) = 100 \cdot 1 =100.
$$
So,
\begin{eqnarray}
\nonumber P( X \geq 120) &=& P\left(\frac{X - 100}{\sqrt{100}} \geq
\frac{120 - 100}{\sqrt{100}}\right) \\
\nonumber &\approx& 1 - \Phi(2) \, = \,  0.0228.
\end{eqnarray}


\section*{Exercise 4:}
\begin{enumerate}%[\indent \bf a)]
\item In this table we report the joint probability distribution of the two dice:
$$
\begin{array}{c|ccccccc}
 & 1 & 2 & 3 & 4 & 5 & 6 & \\
\hline
1 & 1/36 & 1/36 & 1/36 & \multicolumn{1}{c|}{1/36} & 1/36 & 1/36 \\
2 & 1/36 & 1/36 & 1/36 & \multicolumn{1}{c|}{1/36} & 1/36 & 1/36 \\
3 & 1/36 & 1/36 & 1/36 & \multicolumn{1}{c|}{1/36} & 1/36 & 1/36 \\
4 & 1/36 & 1/36 & 1/36 & \multicolumn{1}{c|}{1/36} & 1/36 & 1/36 \\
\cline{2-7}
5 & 1/36 & 1/36 & 1/36 & \multicolumn{1}{c|}{1/36} & 1/36 & 1/36 \\
6 & 1/36 & 1/36 & 1/36 & \multicolumn{1}{c|}{1/36} & 1/36 & 1/36 \\
\end{array}
$$

The possible values of $S$ are 0, 1 or 2. In this table above, the left top square correspond to $S=0$, the right bottom squere to $S=2$ and the other two correspond to $S=1$.
We have then the distribution of $S$:
$$
\begin{array}{c|ccc}
s_i & 0 & 1 & 2\\
\hline
p_{s_i}  = P(S=s_i) & 16/36 & 16/36 & 4/36
\end{array}
$$

\item From the joint distribution of the two dice we can deduce par counting the joint probability of $R$ and $S$:
$$
\begin{array}{c|ccccccc}
\begin{array}{cc}
&R\\
S&
\end{array} & 1 & 2 & 3 & 4 & 5 & 6 & \\
\hline
0 & 1/36 & 3/36 & 5/36 & 7/36 & 0 & 0 \\
1 & 0 & 0 & 0 & 0 & 8/36 & 8/36 \\
2 & 0 & 0 & 0 & 0 & 1/36 & 3/36 \\
\end{array}
$$
\smallskip

\item Counter-exemple: $P(R=1, S=1) = 0 \neq P(R=1)\cdot P(S=1) = (1/6)\cdot(16/36)=16/36^2.$
$X$ et $Y$ are then dependent.
\smallskip

\item By definition:
$$
P(R=r_i | S=1) = \frac{P(R=r_i, S=1)}{P(S=1)}, \quad \mbox{with}\quad r_1=1,\ldots,r_6=6.
$$
As $P(S=1) = 16/36$, we obtain:
$$
\begin{array}{c|ccc}
r_i|S=1 & 5 & 6\\
\hline
P(R=r_i|S=1) & 1/2 & 1/2
\end{array}
$$
\end{enumerate}


\section*{Exercise 5:}

\begin{enumerate}
  \item The probability distribution of $X$ is
  \begin{equation*}
    P(X=x)=\frac{1}{4}  %, \quad x\in \{1,2,3,4\},
  \end{equation*}
for all $x=1,2,3,4$. And the distribution of $Y\vert X=x$ is:
  \begin{equation}
  P(Y=y\vert X=x)=\frac{1}{10-(x-1)} %, \quad x \in \{x, x+1,...,10\}
  \end{equation}
for all $y=x, x+1,...,10$.

  \item The joint distribution of $X$ and $Y$ can be obtained by the following connection:
\begin{equation*}
P(X=x,Y=y)=P(Y=y\vert X=x) P(X=x)=\frac{1}{10-(x-1)} \times \frac{1}{4}  %,y \geq x, \quad x\in \{1,2,3,4\}
\end{equation*}
for $y \geq x$ and $x=1,2,3,4$.

In the table it is:
$$
\begin{array}{c|c|c|c|c|c|c|c|c|c|c}
  %\hline
   & Y=1 & Y=2 & Y=3 & Y=4 & Y=5 & Y=6 & Y=7 & Y=8 & Y=9 & Y=10 \\ \hline
  X=1 & 1/40 & 1/40 & 1/40 & 1/40 & 1/40 & 1/40 & 1/40 & 1/40 & 1/40 & 1/40 \\ \hline
  X=2 & 0 & 1/36 & 1/36 & 1/36 & 1/36 & 1/36 & 1/36 & 1/36 & 1/36 & 1/36 \\ \hline
  X=3 & 0 & 0 & 1/32 & 1/32 & 1/32 & 1/32 & 1/32 & 1/32 & 1/32 & 1/32 \\ \hline
  X=4 & 0 & 0 & 0 & 1/28 & 1/28 & 1/28 & 1/28 & 1/28 & 1/28 & 1/28 \\
  %\hline
\end{array}
$$



\end{enumerate}


\section*{Exercise 6 (Optional):}


\begin{enumerate}
\item Using the hint, we know $P(Z \geq  \zeta) = P (\exp^{\{Z\}}\geq \exp^{\{\zeta\}})$

Let $\exp^{\{Z\}}$ be a random variable $X$. So we can write down its distribution:
$$
\begin{array}{c|cc}
x_i & \exp^{0}=1 & \exp^{1}\\
\hline
p_{x_i}  = P(X=x_i) & 1-p & p
\end{array}
$$

$P(Z \geq  \zeta) = P (\exp^{\{Z\}}\geq \exp^{\{\zeta\}})= P(X \geq \exp^{\{\zeta\}})$

By making use of Markov's inequality,
 \begin{equation*}
P(X \geq \exp^{\{\zeta\}}) \leq \frac{E(X)}{\exp^{\{\zeta\}}} = \frac{p\cdot1+(1-p)\cdot \exp^{\{1\}}}{\exp^{\{\zeta\}}}=\frac{1-p(1-\exp^{\{1\}})}{\exp^{\{\zeta\}}}
\end{equation*}

\item $X$ is the sum of a sequence of independent and identically distributed Bernoulli random variables. So $X \sim Binomial(n,p)$.

\begin{itemize}
 \item[2.1] $X \sim B(n,p)$. X is a discrete random variable. $E(X)=np$
\item[2.2] We know $E(X)=np$, so we replace $np$ in Equation (1) by $E(X)$.
  \begin{eqnarray*}
RHD &=& E[X(X-1)]+np(1-np)\\
&=& E[X(X-1)]+E(X)[1-E(X)] \\
&=& E(X^2)-E(X)+E(X)-E(X)^2\\
&=& E(X^2)-E(X)^2 \\
&=& \text{Var}(X)
\end{eqnarray*}

\item[2.3] We know $E[X^2]\leq n^2\beta^2$, and we subtract $E(X)^2$ for two sides, finding that
$$E[X^2]-E(X)^2\leq n^2\beta^2-E(X)^2$$

The left hand side is $Var(X)$, and the right hand side is $n^2\beta^2-n^2p^2$. \\
So $\text{Var}(X) \leq n^2(\beta^2 -p^2)$

\item[2.4] By making use of Chebyshev's inequality,
$$  P\Big( \vert X-np \vert \geq nE[Y] \Big)  \leq  \frac{\text{Var}(X-np)}{(nE(Y))^2}$$

$\text{Var}(X-np)=\text{Var}(X)= E[X(X-1)]+np(1-np) \leq n^2(\beta^2 -p^2)$\\

As $Y$ is a Poisson random variable, $E(Y)=\lambda$.

So
 \begin{eqnarray*}
  P\Big( \vert X-np \vert \geq nE[Y] \Big)  &\leq&  \frac{E[X(X-1)]+np(1-np)}{(nE[Y])^2}\\
&\leq&   \frac{ n^2(\beta^2 -p^2)}{(n\lambda)^2}= \left(\frac{\beta -p }{\lambda}\right) \left(\frac{\beta + p}{\lambda} \right)
 \end{eqnarray*}

\end{itemize}
\end{enumerate}

\end{document}
